from collections import Counter

class DBKnowledge:
    """
    [Core Brain] ì±—ë´‡ì˜ ì§€ëŠ¥, ì§€ì‹ ê²€ìƒ‰, RAG, ë©”íƒ€ë°ì´í„° ì¡°íšŒë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    V306 ìˆ˜ì •: ê²€ìƒ‰ì–´ ëˆ„ë½ ë²„ê·¸ ìˆ˜ì • (Model, Item, Query Keyword ëª¨ë‘ ê²€ìƒ‰)
    """
    def __init__(self, supabase_client):
        self.supabase = supabase_client

    # =========================================================
    # [Helper] ë°ì´í„° ì •ê·œí™”
    # =========================================================
    def _normalize_tags(self, raw_tags):
        if not raw_tags or str(raw_tags).lower() in ['none', 'nan', 'null']:
            return "ê³µí†µ"
        tags = [t.strip() for t in str(raw_tags).split(',')]
        seen = set()
        clean_tags = []
        for tag in tags:
            if tag and tag not in seen:
                clean_tags.append(tag)
                seen.add(tag)
        return ", ".join(clean_tags) if clean_tags else "ê³µí†µ"

    def _clean_text(self, text):
        if not text or str(text).lower() in ['none', 'nan', 'null', 'ë¯¸ì§€ì •']:
            return "ë¯¸ì§€ì •"
        return str(text).strip()

    def keep_alive(self):
        try: self.supabase.table("knowledge_base").select("id").limit(1).execute()
        except: pass

    # =========================================================
    # [Core] ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ (ì§€ëŠ¥ í•µì‹¬)
    # =========================================================
    def get_penalty_counts(self):
        try:
            res = self.supabase.table("knowledge_blacklist").select("source_id").execute()
            return Counter([r['source_id'] for r in res.data])
        except: return {}

    def save_relevance_feedback(self, query, doc_id, t_name, score, query_vec=None, reason=None):
        try:
            payload = {
                "query_text": query.strip(), "doc_id": doc_id, "table_name": t_name,
                "relevance_score": score, "reason": reason
            }
            if query_vec: payload["query_embedding"] = query_vec
            self.supabase.table("relevance_feedback").insert(payload).execute()
            return True
        except: return False

    def get_semantic_context_blacklist(self, query_vec):
        try:
            res = self.supabase.rpc("match_relevance_feedback_batch", {
                "input_embedding": query_vec, "match_threshold": 0.95
            }).execute()
            if res.data:
                return {(item['table_name'], item['doc_id']) for item in res.data if item['relevance_score'] < 0}
            return set()
        except: return set()

    def match_filtered_db(self, rpc_name, query_vec, threshold, intent, query_text, context_blacklist=None):
        """
        [V306 í•µì‹¬ ìˆ˜ì •] ê²€ìƒ‰ì–´ ì¡°í•© ë¡œì§ ì „ë©´ ìˆ˜ì •
        - ê¸°ì¡´: Intentê°€ ìˆìœ¼ë©´ ì¼ë°˜ í‚¤ì›Œë“œë¥¼ ë¬´ì‹œí•¨ (ë²„ê·¸)
        - ìˆ˜ì •: Intent(ëª¨ë¸, í•­ëª©) + Query Keywordsë¥¼ ëª¨ë‘ í•©ì§‘í•©(Union)ìœ¼ë¡œ ê²€ìƒ‰
        """
        try:
            # 1. Vector Search (ì„ë² ë”© ê²€ìƒ‰)
            vector_results = self.supabase.rpc(rpc_name, {"query_embedding": query_vec, "match_threshold": threshold, "match_count": 40}).execute().data or []
            
            # 2. Keyword Search (í‚¤ì›Œë“œ ê²€ìƒ‰) - ì—¬ê¸°ì„œ ë†“ì¹œ ë¬¸ì„œë¥¼ ì¡ì•„ì•¼ í•¨
            search_candidates = set()
            
            # (1) ì˜ë„ëœ íƒ€ê²Ÿ ëª¨ë¸ëª… ì¶”ê°€ (ì˜ˆ: HAAS-4000)
            if intent.get('target_model') and intent['target_model'] not in ['ë¯¸ì§€ì •', 'ê³µí†µ', 'none']:
                search_candidates.add(intent['target_model'].strip())
                
            # (2) ì˜ë„ëœ íƒ€ê²Ÿ í•­ëª© ì¶”ê°€ (ì˜ˆ: ì±„ìˆ˜ëŸ‰)
            if intent.get('target_item') and intent['target_item'] not in ['ë¯¸ì§€ì •', 'ê³µí†µ', 'none']:
                search_candidates.add(intent['target_item'].strip())
            
            # (3) [ë³µêµ¬ëœ ë¡œì§] ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì¼ë°˜ ëª…ì‚¬ë“¤ë„ ë¬´ì¡°ê±´ ì¶”ê°€
            # ê¸°ì¡´ì—ëŠ” ìœ„ (1),(2)ê°€ ìˆìœ¼ë©´ ì´ê±¸ ê±´ë„ˆë›°ì–´ì„œ ë¬¸ì œì˜€ìŒ
            ignore_words = ['ì•Œë ¤ì¤˜', 'ì–´ë–»ê²Œ', 'êµì²´', 'ë°©ë²•', 'ì¤€ë¹„ë¬¼', 'í•´ì¤˜', 'ìˆì–´', 'ë‚˜ìš”', 'ì¸ê°€ìš”']
            words = query_text.split()
            for w in words:
                if len(w) >= 2 and w not in ignore_words:
                    search_candidates.add(w)
            
            keyword_results = []
            if search_candidates:
                t_name = "manual_base" if "manual" in rpc_name else "knowledge_base"
                query_builder = self.supabase.table(t_name).select("*")
                or_conditions = []
                
                for kw in search_candidates:
                    if not kw: continue
                    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë“± ì•ˆì „ì¥ì¹˜
                    clean_kw = kw.replace("'", "").replace('"', "")
                    if t_name == "manual_base":
                        or_conditions.append(f"measurement_item.ilike.%{clean_kw}%")
                        or_conditions.append(f"model_name.ilike.%{clean_kw}%")
                        or_conditions.append(f"content.ilike.%{clean_kw}%")
                    else:
                        or_conditions.append(f"measurement_item.ilike.%{clean_kw}%")
                        or_conditions.append(f"issue.ilike.%{clean_kw}%")
                        or_conditions.append(f"solution.ilike.%{clean_kw}%")
                
                if or_conditions:
                    # ë„ˆë¬´ ê¸´ ì¿¼ë¦¬ ë°©ì§€ë¥¼ ìœ„í•´ ë‚˜ëˆ ì„œ ì²˜ë¦¬í•˜ê±°ë‚˜, ìƒìœ„ 30ê°œë§Œ ì¡°íšŒ
                    final_filter = ",".join(or_conditions)
                    res = query_builder.or_(final_filter).limit(30).execute()
                    if res.data:
                        for d in res.data:
                            # í‚¤ì›Œë“œë¡œ ì°¾ì€ ë¬¸ì„œëŠ” ì‹ ë¢°ë„ ìµœìƒ(0.99) ë¶€ì—¬
                            d['similarity'] = 0.99 
                            keyword_results.append(d)

            # 3. ê²°ê³¼ ë³‘í•© (Vector + Keyword)
            merged_map = {}
            for d in vector_results: merged_map[d['id']] = d
            for d in keyword_results: merged_map[d['id']] = d 
                
            final_results_list = list(merged_map.values())
            filtered_results = []
            
            # 4. í‚¤ì›Œë“œ ì ìˆ˜ ë³´ì • (Re-scoring)
            keywords = [k for k in query_text.split() if len(k) > 1]
            t_name = "manual_base" if "manual" in rpc_name else "knowledge_base"

            for d in final_results_list:
                if context_blacklist and (t_name, d['id']) in context_blacklist: continue
                
                final_score = d.get('similarity') or 0
                
                # ë³¸ë¬¸(Content)ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê°€ì‚°ì 
                content = (d.get('content') or d.get('solution') or "").lower()
                mfr_model = (d.get('manufacturer', '') + d.get('model_name', '')).lower()
                
                for kw in keywords:
                    kw_lower = kw.lower()
                    if kw_lower in content: final_score += 0.05
                    if kw_lower in mfr_model: final_score += 0.1 # ëª¨ë¸ëª… ì¼ì¹˜ ì‹œ í° ê°€ì‚°ì 
                
                d['similarity'] = min(final_score, 1.0) # 1.0 ì´ˆê³¼ ë°©ì§€
                filtered_results.append(d)
                
            return filtered_results
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì‹œìŠ¤í…œ ë©ˆì¶¤ ë°©ì§€)
            print(f"DB Search Error: {e}")
            return []

    def search_keyword_fallback(self, query_text):
        keywords = [k for k in query_text.split() if len(k) >= 2]
        if not keywords: return []
        # ê°€ì¥ ê¸´ ë‹¨ì–´(í•µì‹¬ í‚¤ì›Œë“œì¼ í™•ë¥  ë†’ìŒ)ë¡œ ë¹„ìƒ ê²€ìƒ‰
        target_keyword = max(keywords, key=len)
        try:
            res = self.supabase.table("manual_base").select("*").or_(f"content.ilike.%{target_keyword}%,model_name.ilike.%{target_keyword}%").limit(5).execute()
            docs = res.data
            for d in docs: d['similarity'] = 0.98; d['source_table'] = 'manual_base'; d['is_verified'] = False 
            return docs
        except: return []

    # =========================================================
    # [Knowledge Graph] ì§€ì‹ ê·¸ë˜í”„
    # =========================================================
    def save_knowledge_triples(self, doc_id, triples):
        if not triples: return False
        try:
            data = []
            for t in triples:
                if t.get('source') and t.get('target'):
                    data.append({"source": self._clean_text(t['source']), "relation": t.get('relation', 'related_to'), "target": self._clean_text(t['target']), "doc_id": doc_id})
            if data: self.supabase.table("knowledge_graph").insert(data).execute(); return True
            return False
        except: return False

    def search_graph_relations(self, keyword):
        try: return self.supabase.table("knowledge_graph").select("*").or_(f"source.ilike.%{keyword}%,target.ilike.%{keyword}%").limit(20).execute().data
        except: return []

    def update_graph_triple(self, rel_id, new_source, new_relation, new_target):
        try:
            payload = {"source": self._clean_text(new_source), "relation": new_relation, "target": self._clean_text(new_target)}
            res = self.supabase.table("knowledge_graph").update(payload).eq("id", rel_id).execute()
            return True if res.data else False
        except: return False

    def delete_graph_triple(self, rel_id):
        try: self.supabase.table("knowledge_graph").delete().eq("id", rel_id).execute(); return True
        except: return False

    def bulk_rename_graph_node(self, old_name, new_name, target_scope="all"):
        try:
            count = 0
            if target_scope in ["source", "all"]:
                res = self.supabase.table("knowledge_graph").update({"source": self._clean_text(new_name)}).eq("source", old_name).execute()
                if res.data: count += len(res.data)
            if target_scope in ["target", "all"]:
                res = self.supabase.table("knowledge_graph").update({"target": self._clean_text(new_name)}).eq("target", old_name).execute()
                if res.data: count += len(res.data)
            return True, count
        except: return False, 0

    # =========================================================
    # [Metadata Utils] ì±—ë´‡ì´ ì°¸ì¡°í•˜ëŠ” ë©”íƒ€ë°ì´í„° (ì§€ëŠ¥ì˜ ì›ì²œ)
    # =========================================================
    def get_doc_metadata_by_id(self, doc_id, source_type):
        try:
            t_name = "knowledge_base" if source_type == "knowledge" else "manual_base"
            res = self.supabase.table(t_name).select("manufacturer, model_name, measurement_item").eq("id", doc_id).execute()
            if res.data: return res.data[0]
            return {}
        except: return {}

    def search_inventory_for_chat(self, query_text):
        try:
            stop_words = ['ì¬ê³ ', 'ìˆ˜ëŸ‰', 'ëª‡ê°œ', 'ëª‡', 'ê°œ', 'ìˆì–´', 'ìˆë‚˜ìš”', 'ì•Œë ¤ì¤˜', 'í™•ì¸', 'ì¡°íšŒ', 'ì–´ë””', 'ìˆë‹ˆ', 'í˜„í™©', 'ë³´ì—¬ì¤˜', 'ì†Œëª¨í’ˆ']
            keywords = [k for k in query_text.split() if k not in stop_words and len(k) >= 2]
            if not keywords: return None
            res = self.supabase.table("inventory_items").select("*").or_(",".join([f"item_name.ilike.%{kw}%" for kw in keywords])).execute()
            if not res.data: return f"ğŸ” **'{', '.join(keywords)}'**ì— ëŒ€í•œ ì¬ê³  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
            msg = f"ğŸ“¦ **ì¬ê³  ê²€ìƒ‰ ê²°ê³¼ ({len(res.data)}ê±´):**\n"
            for item in res.data[:10]: msg += f"- [{item.get('category')}] **{item.get('item_name')}**: {item.get('current_qty')}ê°œ ({item.get('location')})\n"
            return msg
        except Exception as e: return f"ì¬ê³  ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"

    # =========================================================
    # [Knowledge Manage] ì§€ì‹ ê´€ë¦¬ (Admin ê¸°ëŠ¥)
    # =========================================================
    def search_knowledge_for_admin(self, keyword):
        try: return self.supabase.table("knowledge_base").select("*").or_(f"issue.ilike.%{keyword}%,solution.ilike.%{keyword}%").order("created_at", desc=True).limit(20).execute().data
        except: return []

    def update_knowledge_item(self, doc_id, new_issue, new_sol, mfr, model, item):
        try:
            from logic_ai import get_embedding
            payload = {"issue": new_issue, "solution": new_sol, "manufacturer": self._clean_text(mfr), "model_name": self._clean_text(model), "measurement_item": self._normalize_tags(item), "embedding": get_embedding(f"ì¦ìƒ: {new_issue}\ní•´ê²°: {new_sol}"), "semantic_version": 2}
            res = self.supabase.table("knowledge_base").update(payload).eq("id", doc_id).execute()
            return True if res.data else False
        except: return False

    def update_record_labels(self, table_name, row_id, mfr, model, item):
        try:
            payload = {"manufacturer": self._clean_text(mfr), "model_name": self._clean_text(model), "measurement_item": self._normalize_tags(item), "semantic_version": 1, "review_required": False}
            res = self.supabase.table(table_name).update(payload).eq("id", row_id).execute()
            return (True, "ì„±ê³µ") if res.data else (False, "ì‹¤íŒ¨")
        except Exception as e: return (False, str(e))
    
    def update_file_labels(self, table_name, file_name, mfr, model, item):
        try:
            payload = {"manufacturer": self._clean_text(mfr), "model_name": self._clean_text(model), "measurement_item": self._normalize_tags(item), "semantic_version": 1, "review_required": False}
            res = self.supabase.table(table_name).update(payload).eq("file_name", file_name).or_(f'manufacturer.eq.ë¯¸ì§€ì •,manufacturer.is.null,manufacturer.eq.""').execute()
            return True, f"{len(res.data)}ê±´ ì¼ê´„ ë¶„ë¥˜ ì™„ë£Œ"
        except Exception as e: return False, str(e)
    
    def promote_to_knowledge(self, issue, solution, mfr, model, item, author="ìµëª…"):
        try:
            from logic_ai import get_embedding
            payload = {"domain": "ê¸°ìˆ ì§€ì‹", "issue": issue, "solution": solution, "embedding": get_embedding(issue), "semantic_version": 1, "is_verified": True, "manufacturer": self._clean_text(mfr), "model_name": self._clean_text(model), "measurement_item": self._normalize_tags(item), "registered_by": author}
            res = self.supabase.table("knowledge_base").insert(payload).execute()
            return (True, "ì„±ê³µ") if res.data else (False, "ì‹¤íŒ¨")
        except Exception as e: return (False, str(e))
    
    def update_vector(self, table_name, row_id, vec):
        try: self.supabase.table(table_name).update({"embedding": vec}).eq("id", row_id).execute(); return True
        except: return False

    def delete_record(self, table_name, row_id):
        try:
            res = self.supabase.table(table_name).delete().eq("id", row_id).execute()
            return (True, "ì„±ê³µ") if res.data else (False, "ì‹¤íŒ¨")
        except Exception as e: return (False, str(e))
    
    def get_community_posts(self):
        try: return self.supabase.table("community_posts").select("*").order("created_at", desc=True).execute().data
        except: return []

    def add_community_post(self, author, title, content, mfr, model, item):
        try:
            payload = {"author": author, "title": title, "content": content, "manufacturer": self._clean_text(mfr), "model_name": self._clean_text(model), "measurement_item": self._normalize_tags(item)}
            res = self.supabase.table("community_posts").insert(payload).execute()
            return True if res.data else False
        except: return False

    def update_community_post(self, post_id, title, content, mfr, model, item):
        try:
            payload = {"title": title, "content": content, "manufacturer": self._clean_text(mfr), "model_name": self._clean_text(model), "measurement_item": self._normalize_tags(item)}
            res = self.supabase.table("community_posts").update(payload).eq("id", post_id).execute()
            return True if res.data else False
        except: return False

    def delete_community_post(self, post_id):
        try: res = self.supabase.table("community_posts").delete().eq("id", post_id).execute(); return True if res.data else False
        except: return False

    def get_comments(self, post_id):
        try: return self.supabase.table("community_comments").select("*").eq("post_id", post_id).order("created_at").execute().data
        except: return []

    def add_comment(self, post_id, author, content):
        try: res = self.supabase.table("community_comments").insert({"post_id": post_id, "author": author, "content": content}).execute(); return True if res.data else False
        except: return False
