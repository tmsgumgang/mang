import time
import json
from concurrent.futures import ThreadPoolExecutor
from logic_ai import *

def normalize_model_name(text):
    """
    [V188] ëª¨ë¸ëª… ì •ê·œí™” í—¬í¼
    """
    if not text: return ""
    return str(text).lower().replace(" ", "").replace("-", "").replace("_", "")

def filter_candidates_logic(candidates, intent, penalties, strict_mode=True):
    """
    [V205] í•„í„°ë§ ë¡œì§ ì—…ë°ì´íŠ¸
    - 3ë‹¨ê³„ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ë°œêµ´ëœ ë¬¸ì„œ(ì ìˆ˜ 0.85)ëŠ” ì—„ê²©í•œ í•„í„°ë§ì„ ë©´ì œí•´ì£¼ëŠ” 'í”„ë¦¬íŒ¨ìŠ¤' ê¶Œí•œ ë¶€ì—¬
    - [V248] ê·¸ë˜í”„ê°€ ì†Œí™˜í•œ ì›ë³¸ ë¬¸ì„œ(ì ìˆ˜ 0.95)ë„ í”„ë¦¬íŒ¨ìŠ¤ ê¶Œí•œ ë¶€ì—¬
    """
    filtered = []
    
    # 1. Intent(ì˜ë„) ë°ì´í„° ì •ê·œí™”
    t_mfr = normalize_model_name(intent.get('target_mfr') or 'ë¯¸ì§€ì •')
    raw_t_model = str(intent.get('target_model') or 'ë¯¸ì§€ì •')
    t_model = normalize_model_name(raw_t_model)
    
    raw_t_item = str(intent.get('target_item') or 'ê³µí†µ').strip()
    normalized_target = raw_t_item.replace(" ", "").lower()
    t_item = normalize_model_name(raw_t_item)
    
    generic_keywords = ['ê³µí†µ', 'ë¯¸ì§€ì •', 'ì•Œìˆ˜ì—†ìŒ', 'none', 'general', 'ê¸°íƒ€']
    
    # ëª¨ë¸ëª…ì´ íŠ¹ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ë…ì  ëª¨ë“œ íŠ¸ë¦¬ê±° ì¡°ê±´)
    is_model_locked = (t_model not in generic_keywords) and (len(t_model) > 1)
    
    # ì•„ì´í…œëª…ì´ íŠ¹ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
    is_specific_target = (t_item not in generic_keywords) and (len(t_item) > 1)
    
    # ìƒí˜¸ ë°°íƒ€ì  ë©”ì´ì € ì¹´í…Œê³ ë¦¬
    major_categories = ['tn', 'tp', 'toc', 'cod', 'ph', 'ss', 'ì±„ìˆ˜íŒí”„', 'ì±„ìˆ˜ê¸°']

    for d in candidates:
        u_key = f"{'EXP' if 'solution' in d else 'MAN'}_{d.get('id')}"
        if d.get('semantic_version') != 1 and d.get('source_table') != 'knowledge_graph': # [V239] ê·¸ë˜í”„ ë°ì´í„°ëŠ” ë²„ì „ì²´í¬ íŒ¨ìŠ¤
            if d.get('semantic_version') != 1 and d.get('semantic_version') != 2: # V237ë¶€í„° semantic_version 2 ì‚¬ìš©í•¨
                continue

        # 2. ë¬¸ì„œ(Doc) ë°ì´í„° ì •ê·œí™”
        d_mfr_raw = str(d.get('manufacturer') or '')
        d_model_raw = str(d.get('model_name') or '')
        d_item_raw = str(d.get('measurement_item') or '')
        
        d_mfr = normalize_model_name(d_mfr_raw)
        d_model = normalize_model_name(d_model_raw)
        d_item = normalize_model_name(d_item_raw)
        
        similarity = d.get('similarity') or 0
        is_hybrid_hit = (similarity > 0.98) 
        
        # [NEW] 3ë‹¨ê³„ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ë¬¸ì„œëŠ” ì ìˆ˜ê°€ 0.85ë¡œ ê³ ì •ë¨ -> í”„ë¦¬íŒ¨ìŠ¤ ëŒ€ìƒ
        is_keyword_hit = (similarity == 0.85)
        # [V248 NEW] ê·¸ë˜í”„ê°€ ì†Œí™˜í•œ ë¬¸ì„œëŠ” ì ìˆ˜ê°€ 0.95ë¡œ ê³ ì •ë¨ -> í”„ë¦¬íŒ¨ìŠ¤ ëŒ€ìƒ
        is_graph_summon = (similarity == 0.95)

        # ë¬¸ì„œê°€ 'ê³µí†µ' ëª¨ë¸ì¸ì§€ í™•ì¸
        is_doc_model_common = any(k in d_model_raw.lower() for k in generic_keywords) or d_model == ""

        if strict_mode:
            # ---------------------------------------------------------------
            # [V205 í•µì‹¬] í‚¤ì›Œë“œ íˆíŠ¸(ê°•ì œë°œêµ´) ë°ì´í„°ëŠ” í•„í„° ê²€ì‚¬ë¥¼ ë©´ì œ
            # [V239 ì¶”ê°€] ì§€ì‹ ê·¸ë˜í”„(knowledge_graph) ë°ì´í„°ë„ ë©´ì œ (ìœ ì‚¬ë„ 0.99)
            # [V248 ì¶”ê°€] ê·¸ë˜í”„ ì†Œí™˜ ë¬¸ì„œ(is_graph_summon)ë„ ë©´ì œ
            # ---------------------------------------------------------------
            if not is_keyword_hit and not is_graph_summon and d.get('source_table') != 'knowledge_graph':
                # 1. ëª¨ë¸ ë…ì  ëª¨ë“œ ì²´í¬
                if is_model_locked and not is_doc_model_common:
                    if d_model != '' and t_model not in d_model and d_model not in t_model:
                        continue 

                # 2. ì¹´í…Œê³ ë¦¬ êµì°¨ ê²€ì¦
                if is_specific_target:
                    doc_identity = d_item_raw.lower() + " " + d_model_raw.lower()
                    is_identity_mismatch = False
                    for cat in major_categories:
                        if cat in doc_identity:
                            if cat not in raw_t_item.lower() and raw_t_item.lower() not in cat:
                                if not (('ì±„ìˆ˜' in cat and 'ì±„ìˆ˜' in raw_t_item.lower()) or 
                                        ('íŒí”„' in cat and 'íŒí”„' in raw_t_item.lower())):
                                    if not is_hybrid_hit:
                                        is_identity_mismatch = True
                                        break
                    if is_identity_mismatch: continue

                # 3. SQL ê²€ì¦ ë° í‚¤ì›Œë“œ í™•ì¸
                if is_specific_target and not is_hybrid_hit:
                    d_content_full = (d_mfr_raw + d_model_raw + d_item_raw + str(d.get('content') or '')).lower().replace(" ", "")
                    if normalized_target not in d_content_full:
                        if similarity < 0.95:
                            continue 

                # 4. ëª¨ë¸ëª… ì¼ë°˜ ë°©í™”ë²½
                if t_model != 'ë¯¸ì§€ì •':
                    if not is_doc_model_common and d_model != '' and t_model not in d_model and d_model not in t_model and not is_hybrid_hit:
                        if similarity < 0.95:
                            continue

        score = similarity
        
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ê°ì 
        score -= (penalties.get(u_key, 0) * 0.1)
        if d.get('is_verified'): score += 0.15
        
        # íƒ€ê²Ÿ ëª¨ë¸ ì¼ì¹˜ ì‹œ ê°€ì‚°ì 
        if is_model_locked and (t_model in d_model or d_model in t_model):
            score += 10.0 

        # í‚¤ì›Œë“œ ê°€ì‚°ì 
        if is_specific_target and (raw_t_item.lower() in d_item_raw.lower() or raw_t_item.lower() in d_model_raw.lower()):
            score += 0.2

        filtered.append({**d, 'final_score': score, 'u_key': u_key})
        
    return sorted(filtered, key=lambda x: x['final_score'], reverse=True)[:8]

def perform_unified_search(ai_model, db, user_q, u_threshold):
    """
    [V248] 4ë‹¨ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Graph + Vector + Metadata + Keyword)
    - ê·¸ë˜í”„ì—ì„œ ë°œê²¬ëœ ì§€ì‹ì˜ 'ì›ë³¸ ë¬¸ì„œ'ë¥¼ ê°•ì œ ì†Œí™˜í•˜ì—¬ ê²°ê³¼ì— í¬í•¨ (Missing Link í•´ê²°)
    """
    # 1. ì´ˆê¸° ì§„ì… (ë³‘ë ¬ ì²˜ë¦¬)
    with ThreadPoolExecutor() as executor:
        future_vec = executor.submit(get_embedding, user_q)
        future_intent = executor.submit(analyze_search_intent, ai_model, user_q)
        q_vec = future_vec.result()
        intent = future_intent.result()
    
    if not intent or not isinstance(intent, dict):
        intent = {"target_mfr": "ë¯¸ì§€ì •", "target_model": "ë¯¸ì§€ì •", "target_item": "ê³µí†µ"}

    is_specific_search = (intent.get('target_item') != 'ê³µí†µ') or (intent.get('target_model') != 'ë¯¸ì§€ì •')
    effective_threshold = 0.2 if is_specific_search else u_threshold

    # 2. ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ë³‘ë ¬)
    with ThreadPoolExecutor() as executor:
        future_blacklist = executor.submit(db.get_semantic_context_blacklist, q_vec)
        future_penalties = executor.submit(db.get_penalty_counts)
        context_blacklist = future_blacklist.result()
        penalties = future_penalties.result()

    # -----------------------------------------------------------
    # [Step 0] ğŸ•¸ï¸ ì§€ì‹ ê·¸ë˜í”„(Graph RAG) ë™ì‹œ ìˆ˜ìƒ‰ & ì›ë³¸ ID í™•ë³´ (V248 NEW)
    # -----------------------------------------------------------
    keywords = [k for k in user_q.split() if len(k) >= 2]
    if intent.get('target_item') and intent.get('target_item') != 'ê³µí†µ':
        keywords.append(intent.get('target_item'))
    
    graph_docs = []
    # [V248] ì›ë³¸ ë¬¸ì„œ IDë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ì§‘í•©
    graph_source_ids = {'manual': set(), 'knowledge': set()} 

    if keywords:
        graph_relations = []
        for kw in set(keywords):
            # db_servicesì— ìˆëŠ” ê·¸ë˜í”„ ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ
            rels = db.search_graph_relations(kw)
            if rels: graph_relations.extend(rels)
        
        # ì¤‘ë³µ ì œê±° ë° ì›ë³¸ ID ì¶”ì¶œ
        if graph_relations:
            unique_graphs = []
            seen_graphs = set()
            for rel in graph_relations:
                # 1. ê·¸ë˜í”„ ë…¸ë“œ ë°ì´í„° ì €ì¥
                g_key = f"{rel['source']}_{rel['relation']}_{rel['target']}"
                if g_key not in seen_graphs:
                    seen_graphs.add(g_key)
                    unique_graphs.append(rel)
                
                # 2. [V248 í•µì‹¬] ì›ë³¸ ë¬¸ì„œ ID ìˆ˜ì§‘ (ë‚˜ì¤‘ì— ê°•ì œ ì†Œí™˜)
                if rel.get('doc_id'):
                    s_type = rel.get('source_type', 'manual') # ê¸°ë³¸ê°’ manual
                    if s_type == 'knowledge': graph_source_ids['knowledge'].add(rel['doc_id'])
                    else: graph_source_ids['manual'].add(rel['doc_id'])
            
            # ê·¸ë˜í”„ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ 'ê°€ìƒ ë¬¸ì„œ'ë¡œ ì••ì¶•
            if unique_graphs:
                graph_text = "ğŸ’¡ [Graph DB ì¸ê³¼ê´€ê³„ ë¶„ì„ê²°ê³¼]\n"
                for rel in unique_graphs[:7]: # ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ 7ê°œ ì œí•œ
                    rel_type = rel['relation']
                    # ê´€ê³„ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë§¤í•‘ (UIì™€ í†µì¼)
                    rel_korean = {
                        "causes": "ì›ì¸ì´ë‹¤",
                        "part_of": "ë¶€í’ˆì´ë‹¤",
                        "solved_by": "í•´ê²°ì±…ì´ë‹¤",
                        "requires": "í•„ìš”ë¡œ í•œë‹¤",
                        "has_status": "ìƒíƒœë¥¼ ë³´ì¸ë‹¤",
                        "located_in": "ì— ìœ„ì¹˜í•œë‹¤",
                        "manufactured_by": "ì œí’ˆì´ë‹¤"
                    }.get(rel_type, rel_type)
                    
                    graph_text += f"- [{rel['source']}]ëŠ”(ì€) [{rel['target']}]ì˜ '{rel_korean}'.\n"

                graph_docs.append({
                    'id': 999999, # ì„ì‹œ ID
                    'source_table': 'knowledge_graph',
                    'manufacturer': intent.get('target_mfr', 'ê³µí†µ'),
                    'model_name': intent.get('target_model', 'ê³µí†µ'),
                    'measurement_item': intent.get('target_item', 'ê³µí†µ'),
                    'content': graph_text,
                    'similarity': 0.99, # ì‹ ë¢°ë„ ìµœìƒ
                    'is_verified': True,
                    'semantic_version': 2
                })

    # -----------------------------------------------------------
    # [Step 1] ì •ë°€ ê²€ìƒ‰ (ì¸ë±ìŠ¤/í•„í„° ê¸°ë°˜)
    # -----------------------------------------------------------
    with ThreadPoolExecutor() as executor:
        future_m = executor.submit(db.match_filtered_db, "match_manual", q_vec, effective_threshold, intent, user_q, context_blacklist)
        future_k = executor.submit(db.match_filtered_db, "match_knowledge", q_vec, effective_threshold, intent, user_q, context_blacklist)
        m_res = future_m.result()
        k_res = future_k.result()

    # -----------------------------------------------------------
    # [Step 1.5] ğŸ£ ê·¸ë˜í”„ ì›ë³¸ ë¬¸ì„œ ê°•ì œ ì†Œí™˜ (V248 NEW)
    # -----------------------------------------------------------
    # ë²¡í„° ê²€ìƒ‰ì—ì„œ ë†“ì³¤ë”ë¼ë„, ê·¸ë˜í”„ì— ì—°ê²°ëœ ë¬¸ì„œëŠ” ë¬´ì¡°ê±´ ê°€ì ¸ì˜µë‹ˆë‹¤.
    summoned_docs = []
    
    # ë§¤ë‰´ì–¼ ì›ë³¸ ì†Œí™˜
    if graph_source_ids['manual']:
        try:
            ids = list(graph_source_ids['manual'])[:5] # ë„ˆë¬´ ë§ìœ¼ë©´ 5ê°œë§Œ
            res = db.supabase.table("manual_base").select("*").in_("id", ids).execute()
            if res.data:
                for d in res.data:
                    d['similarity'] = 0.95 # ë†’ì€ ì ìˆ˜ ë¶€ì—¬ (ê·¸ë˜í”„ ì¦ê±°ë¬¼)
                    d['source_table'] = 'manual_base'
                    summoned_docs.append(d)
        except Exception as e: print(f"Manual Summon Error: {e}")

    # ì§€ì‹ ì›ë³¸ ì†Œí™˜
    if graph_source_ids['knowledge']:
        try:
            ids = list(graph_source_ids['knowledge'])[:5]
            res = db.supabase.table("knowledge_base").select("*").in_("id", ids).execute()
            if res.data:
                for d in res.data:
                    d['similarity'] = 0.95
                    d['source_table'] = 'knowledge_base'
                    summoned_docs.append(d)
        except Exception as e: print(f"Knowledge Summon Error: {e}")

    # ì†Œí™˜ëœ ë¬¸ì„œë¥¼ ê¸°ì¡´ ê²°ê³¼ì— ë³‘í•©
    m_res += summoned_docs 

    # -----------------------------------------------------------
    # [Step 2] ê´‘ë²”ìœ„ ê²€ìƒ‰ (ì¸ë±ìŠ¤ ë¬´ì‹œ, ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜)
    # -----------------------------------------------------------
    if len(m_res) + len(k_res) < 3:
        relaxed_intent = {"target_mfr": "ë¯¸ì§€ì •", "target_model": "ë¯¸ì§€ì •", "target_item": "ê³µí†µ"}
        with ThreadPoolExecutor() as executor:
            future_m_broad = executor.submit(db.match_filtered_db, "match_manual", q_vec, effective_threshold, relaxed_intent, user_q, context_blacklist)
            future_k_broad = executor.submit(db.match_filtered_db, "match_knowledge", q_vec, effective_threshold, relaxed_intent, user_q, context_blacklist)
            m_res += future_m_broad.result()
            k_res += future_k_broad.result()

    # -----------------------------------------------------------
    # [Step 3] í‚¤ì›Œë“œ ê°•ì œ ë°œêµ´ (ìµœí›„ì˜ ë³´ë£¨)
    # -----------------------------------------------------------
    if len(m_res) + len(k_res) < 3:
        keyword_docs = db.search_keyword_fallback(user_q) 
        if keyword_docs:
            m_res += keyword_docs 

    # 4. ë°ì´í„° í†µí•©
    for r in m_res: 
        if 'source_table' not in r: r['source_table'] = 'manual_base'
    for r in k_res: 
        if 'source_table' not in r: r['source_table'] = 'knowledge_base'
    
    # [ì¤‘ìš”] ê·¸ë˜í”„ ê²°ê³¼ë¥¼ ë§¨ ì•ì— ë°°ì¹˜
    combined_raw = graph_docs + m_res + k_res
    
    # ID ê¸°ë°˜ ì¤‘ë³µ ì œê±° (ì†Œí™˜ëœ ë¬¸ì„œì™€ ë²¡í„° ê²€ìƒ‰ ë¬¸ì„œê°€ ê²¹ì¹  ìˆ˜ ìˆìŒ)
    all_docs = []
    seen_uids = set()
    for doc in combined_raw:
        uid = f"{doc.get('source_table')}_{doc['id']}"
        if uid not in seen_uids:
            seen_uids.add(uid)
            all_docs.append(doc)

    # 5. í•„í„°ë§ ë° ë¦¬ë­í‚¹
    raw_candidates = filter_candidates_logic(all_docs, intent, penalties, strict_mode=True)
    
    if not raw_candidates:
        fallback_candidates = filter_candidates_logic(all_docs, intent, penalties, strict_mode=False)
        raw_candidates = [d for d in fallback_candidates if d['final_score'] > 0.65]

    # ìµœì¢… ìˆœìœ„ ê²°ì • (LLM Rerank)
    final_results = quick_rerank_ai(ai_model, user_q, raw_candidates, intent)
    
    return final_results, intent, q_vec
