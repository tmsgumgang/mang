import streamlit as st
from supabase import create_client, Client
import google.generativeai as genai
import pandas as pd
import PyPDF2
import io
import json
import re
import time
from collections import Counter

# [ë³´ì•ˆ] Streamlit Secrets
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)
    chat_model = genai.GenerativeModel('gemini-2.0-flash') 
    return supabase_client, chat_model

try:
    supabase, ai_model = init_clients()
except Exception as e:
    st.error(f"ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")

# --- [V127] í‘œì¤€ ì¹´í…Œê³ ë¦¬ ë° ë„ë©”ì¸ ì •ì˜ ---
DIRECT_INPUT_LABEL = "ì§ì ‘ ì…ë ¥"
DOMAIN_MAP = {
    "ê¸°ìˆ ì§€ì‹": {
        "ì¸¡ì •ê¸°ê¸°": ["TOC", "TN", "TP", "ì¼ë°˜í•­ëª©", "VOCs", "ë¬¼ë²¼ë£©", "í™©ì‚°í™”", "ë¯¸ìƒë¬¼", "ë°œê´‘ë°•í…Œë¦¬ì•„", "ê¸°íƒ€"],
        "ì±„ìˆ˜ì‹œì„¤": ["íŒí”„", "ë ˆë“€ìƒ¤", "í˜¸ìŠ¤", "ì»¤í”Œë§", "ìº¡ë¡", "ì—¬ê³¼ í•„í„°", "ê¸°íƒ€"],
        "ì „ì²˜ë¦¬/ë°˜ì‘ì¡°": ["ê³µí†µ"], "í†µì‹ /ë°ì´í„°": ["ê³µí†µ"], "ì „ê¸°/ì œì–´": ["ê³µí†µ"], "ì†Œëª¨í’ˆ/ì‹œì•½": ["ê³µí†µ"]
    },
    "í–‰ì •ì ˆì°¨": {
        "ì ê²€/ë³´ê³ ": ["ê³µí†µ"], "êµ¬ë§¤/ì‹ ì²­": ["ê³µí†µ"], "ì•ˆì „/ê·œì •": ["ê³µí†µ"], "ë§¤ë‰´ì–¼/ì§€ì¹¨": ["ê³µí†µ"]
    },
    "ë³µì§€ìƒí™œ": {
        "ë§›ì§‘/ì‹ë‹¹": ["ê³µí†µ"], "ì¹´í˜/í¸ì˜": ["ê³µí†µ"], "ì£¼ì°¨/êµí†µ": ["ê³µí†µ"], "ê¸°ìƒ/ì¬ë‚œ": ["ê³µí†µ"]
    }
}

# --- í•µì‹¬ í—¬í¼ í•¨ìˆ˜ ---
def clean_text_for_db(text):
    if not text: return ""
    text = text.replace("\u0000", "")
    return "".join(ch for ch in text if ch.isprintable() or ch in ['\n', '\r', '\t']).strip()

def get_embedding(text):
    clean_txt = clean_text_for_db(text)
    if not clean_txt: return [0.0] * 768
    result = genai.embed_content(model="models/text-embedding-004", content=clean_txt, task_type="retrieval_document")
    return result['embedding']

def extract_json(text):
    try:
        cleaned = re.sub(r'```json\s*|```', '', text).strip()
        return json.loads(cleaned)
    except: return None

def get_penalty_counts():
    try:
        res = supabase.table("knowledge_blacklist").select("source_id").execute()
        return Counter([r['source_id'] for r in res.data])
    except: return {}

# [V127] ë§¥ë½ ë³´ì¡´ ë¶„í•  (600ì ë³‘í•©)
def semantic_split_v127(text, target_size=1200, min_size=600):
    flat_text = " ".join(text.split())
    sentences = re.split(r'(?<=[.!?])\s+', flat_text)
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= target_size:
            current_chunk += " " + sentence
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk:
        if len(current_chunk) < min_size and chunks: chunks[-1] = chunks[-1] + " " + current_chunk.strip()
        else: chunks.append(current_chunk.strip())
    return chunks

# --- UI ì„¤ì • ---
st.set_page_config(page_title="ê¸ˆê°•ìˆ˜ê³„ AI ì±—ë´‡ V127", layout="centered", initial_sidebar_state="collapsed")
if 'page_mode' not in st.session_state: st.session_state.page_mode = "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰"

st.markdown("""
    <style>
    .fixed-header { position: fixed; top: 0; left: 0; width: 100%; background-color: #004a99; color: white; padding: 10px 0; z-index: 999; text-align: center; box-shadow: 0 4px 10px rgba(0,0,0,0.2); }
    .header-title { font-size: 1.1rem; font-weight: 800; }
    .main .block-container { padding-top: 4.5rem !important; }
    .meta-bar { background-color: rgba(128, 128, 128, 0.15); border-left: 5px solid #004a99; padding: 8px; border-radius: 4px; font-size: 0.8rem; margin-bottom: 10px; display: flex; gap: 15px; }
    </style>
    <div class="fixed-header"><span class="header-title">ğŸŒŠ ê¸ˆê°•ìˆ˜ê³„ ìˆ˜ì§ˆìë™ì¸¡ì •ë§ AI ì±—ë´‡ V127</span></div>
    """, unsafe_allow_html=True)

menu_options = ["ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰", "ğŸ“ ì§€ì‹ ë“±ë¡", "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡", "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬", "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ", "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ"]
st.session_state.page_mode = st.selectbox("â˜° ë©”ë‰´", options=menu_options, index=menu_options.index(st.session_state.page_mode), label_visibility="collapsed")

# --- 1. í†µí•© ì§€ì‹ ê²€ìƒ‰ (ì „ ê¸°ëŠ¥ ë³µêµ¬ ë²„ì „) ---
if st.session_state.page_mode == "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰":
    search_mode = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["ì—…ë¬´ê¸°ìˆ  ğŸ› ï¸", "ìƒí™œì •ë³´ ğŸ´"], horizontal=True, label_visibility="collapsed")
    user_q = st.text_input("ì§ˆë¬¸ ì…ë ¥", label_visibility="collapsed", placeholder="ì¥ë¹„ ëª¨ë¸ëª…ì´ë‚˜ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    if user_q:
        with st.spinner("ì§€ì‹ê³ ì—ì„œ ìµœì ì˜ ë‹µë³€ì„ êµ¬ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                target_domains = ["ê¸°ìˆ ì§€ì‹", "ê¸°ìˆ ìì‚°"] if "ì—…ë¬´ê¸°ìˆ " in search_mode else ["ë³µì§€ìƒí™œ"]
                q_vec = get_embedding(user_q)
                
                # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë° í˜ë„í‹° ë°ì´í„° ë¡œë“œ
                blacklist_ids = [r['source_id'] for r in supabase.table("knowledge_blacklist").select("source_id").eq("query", user_q).execute().data]
                penalty_map = get_penalty_counts()
                
                # í†µí•© ê²€ìƒ‰ ì‹¤í–‰
                m_cands = supabase.rpc("match_manual", {"query_embedding": q_vec, "match_threshold": 0.01, "match_count": 50}).execute().data or []
                k_cands = supabase.rpc("match_knowledge", {"query_embedding": q_vec, "match_threshold": 0.01, "match_count": 50}).execute().data or []
                
                final_pool, seen_ks = [], set()
                for d in (m_cands + k_cands):
                    u_key = f"{'EXP' if 'solution' in d else 'MAN'}_{d.get('id')}"
                    
                    # [V127] ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë° ë„ë©”ì¸ í•„í„°ë§
                    if u_key in blacklist_ids: continue
                    if d.get('domain') not in target_domains or d.get('review_required'): continue
                    
                    # [V127] í˜ë„í‹° ë° ë³´ë„ˆìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
                    penalty = penalty_map.get(u_key, 0) * 0.05
                    raw_c = d.get('solution') or d.get('content') or ""
                    f_print = "".join(raw_c.split())[:60]
                    
                    if u_key not in seen_ks:
                        d['final_score'] = (d.get('similarity') or 0) - penalty
                        d['u_key'] = u_key
                        final_pool.append(d); seen_ks.add(u_key)

                final_pool = sorted(final_pool, key=lambda x: x['final_score'], reverse=True)
                
                if final_pool:
                    st.subheader("ğŸ¤– AI ì „ë¬¸ê°€ ìš”ì•½")
                    ans = ai_model.generate_content(f"ì§ˆë¬¸: {user_q} ë°ì´í„°: {final_pool[:12]}")
                    st.info(ans.text)
                    for i, d in enumerate(final_pool[:10]):
                        with st.expander(f"{i+1}. [{d.get('sub_category','ì¼ë°˜')}] {str(d.get('issue') or 'ìƒì„¸ ì§€ì‹')[:40]}..."):
                            st.markdown(f'<div class="meta-bar"><span>ğŸ¢ ì œì¡°ì‚¬: <b>{d.get("manufacturer","ë¯¸ì§€ì •")}</b></span><span>ğŸ·ï¸ ëª¨ë¸: <b>{d.get("model_name","ë¯¸ì§€ì •")}</b></span><span>ğŸ§ª í•­ëª©: <b>{d.get("measurement_item","ê³µí†µ")}</b></span></div>', unsafe_allow_html=True)
                            st.write(d.get('solution') or d.get('content'))
                else:
                    st.warning("ğŸ” ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ê¸°ì‹¤ì— ê²€í†  ì¤‘ì¸ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”.")
            except Exception as e: st.error(f"ê²€ìƒ‰ ì—”ì§„ ì˜¤ë¥˜: {e}")

# --- 4. ë°ì´í„° ì „ì²´ ê´€ë¦¬ (V127: ëª¨ë“  ì„œë¸Œ íƒ­ ê¸°ëŠ¥ ë³µêµ¬) ---
elif st.session_state.page_mode == "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬":
    tabs = st.tabs(["ğŸ“ ê²½í—˜ ë¦¬íŒŒì´ë„ˆ", "ğŸ“„ ë§¤ë‰´ì–¼ ë¦¬íŒŒì´ë„ˆ", "ğŸ§¹ ì‹œë§¨í‹± ìµœì‹ í™”", "ğŸš¨ ìˆ˜ë™ ë¶„ë¥˜ì‹¤", "ğŸ—ï¸ ì§€ì‹ ì¬ê±´ì¶•"])
    
    with tabs[3]: # ìˆ˜ë™ ë¶„ë¥˜ì‹¤ (V125 ì €ì¥ ë¡œì§ ì™„ê²°)
        st.subheader("ğŸš¨ ì§€ì‹ ìˆ˜ë™ ë¶„ë¥˜ (í‘œì¤€ ì²´ê³„ ì—°ë™)")
        t_sel = st.radio("í…Œì´ë¸”", ["ê²½í—˜", "ë§¤ë‰´ì–¼"], horizontal=True, key="v127_rv")
        t_name = "knowledge_base" if t_sel == "ê²½í—˜" else "manual_base"
        review_list = supabase.table(t_name).select("*").eq("review_required", True).limit(2).execute().data
        
        if not review_list: st.success("ğŸ‰ ê²€í† í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for item in review_list:
                st.markdown(f"**[ë°ì´í„° ì›ë¬¸]**\n{item.get('content') or item.get('solution')}")
                with st.form(key=f"rv_v127_{item['id']}"):
                    c1, c2, c3 = st.columns(3)
                    m_dom = c1.selectbox("ë„ë©”ì¸", list(DOMAIN_MAP.keys()), key=f"d_{item['id']}")
                    m_sub_sel = c2.selectbox("ì„¸ë¶€ë¶„ë¥˜", list(DOMAIN_MAP[m_dom].keys()) + [DIRECT_INPUT_LABEL], key=f"s_{item['id']}")
                    m_sub_txt = c2.text_input("â”” ì§ì ‘ ì…ë ¥", key=f"st_{item['id']}")
                    m_itm_sel = c3.selectbox("ìƒì„¸ í•­ëª©", DOMAIN_MAP[m_dom].get(m_sub_sel, ["ê³µí†µ"]) + [DIRECT_INPUT_LABEL], key=f"i_{item['id']}")
                    m_itm_txt = c3.text_input("â”” ì§ì ‘ ì…ë ¥", key=f"it_{item['id']}")
                    
                    if st.form_submit_button("âœ… ë¶„ë¥˜ í™•ì • ë° ì €ì¥"):
                        f_sub = m_sub_txt if m_sub_sel == DIRECT_INPUT_LABEL else m_sub_sel
                        f_itm = m_itm_txt if m_itm_sel == DIRECT_INPUT_LABEL else m_itm_sel
                        supabase.table(t_name).update({
                            "domain": m_dom, "sub_category": f_sub, "measurement_item": f_itm,
                            "review_required": False, "semantic_version": 1
                        }).eq("id", item['id']).execute()
                        st.toast("ì €ì¥ ì„±ê³µ!"); time.sleep(0.5); st.rerun()

    with tabs[4]: # ì§€ì‹ ì¬ê±´ì¶• (V125 ì™„ì „ ì²­ì‚° ë¡œì§)
        st.subheader("ğŸ—ï¸ ì§€ì‹ ì¬ê±´ì¶• (ë§¥ë½ ë³µì›)")
        files = sorted(list(set([r['file_name'] for r in supabase.table("manual_base").select("file_name").execute().data if r.get('file_name')])))
        t_file = st.selectbox("ìµœì í™” íŒŒì¼ ì„ íƒ", options=files)
        if st.button("ğŸš€ ì§€ì‹ ì „ë©´ ì¬êµ¬ì„±"):
            with st.status("ğŸ—ï¸ ì¬ê±´ì¶• ì§„í–‰ ì¤‘...") as status:
                old_data = supabase.table("manual_base").select("*").eq("file_name", t_file).order("id").execute().data
                if old_data:
                    full_text = " ".join([r['content'] for r in old_data])
                    new_chunks = semantic_split_v127(full_text)
                    for chunk in new_chunks:
                        supabase.table("manual_base").insert({"domain": old_data[0].get('domain','ê¸°ìˆ ì§€ì‹'), "content": clean_text_for_db(chunk), "file_name": t_file, "embedding": get_embedding(chunk), "semantic_version": 1}).execute()
                    for oid in [r['id'] for r in old_data]: supabase.table(t_name).delete().eq("id", oid).execute()
                    status.update(label="ì™„ë£Œ!", state="complete")
                st.rerun()

# --- 2, 3 ë©”ë‰´ (í‘œì¤€ ì²´ê³„ ë°˜ì˜) ---
elif st.session_state.page_mode == "ğŸ“ ì§€ì‹ ë“±ë¡":
    with st.form("reg_v127"):
        f_dom = st.selectbox("ë„ë©”ì¸", list(DOMAIN_MAP.keys()))
        f_iss, f_sol = st.text_input("ì œëª©(Issue)"), st.text_area("í•´ê²°ë°©ë²•(Solution)")
        if st.form_submit_button("ì €ì¥"):
            supabase.table("knowledge_base").insert({"domain": f_dom, "issue": f_iss, "solution": f_sol, "embedding": get_embedding(f_iss), "semantic_version": 1}).execute()
            st.success("ì§€ì‹ ì €ì¥ ì™„ë£Œ!")

elif st.session_state.page_mode == "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡":
    up_f = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
    if up_f and st.button("ğŸš€ ì§€ì‹ í•™ìŠµ ì‹œì‘"):
        up_f.seek(0)
        pdf_r = PyPDF2.PdfReader(io.BytesIO(up_f.read()))
        all_t = "\n".join([p.extract_text() for p in pdf_r.pages if p.extract_text()])
        chunks = semantic_split_v127(all_t)
        for chunk in chunks:
            supabase.table("manual_base").insert({"domain": "ê¸°ìˆ ì§€ì‹", "content": clean_text_for_db(chunk), "file_name": up_f.name, "embedding": get_embedding(chunk), "semantic_version": 1}).execute()
        st.success("í•™ìŠµ ì™„ë£Œ!"); st.rerun()

elif st.session_state.page_mode == "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ":
    st.info("ê¸ˆê°•ìˆ˜ê³„ ëŒ€ì›ë“¤ì˜ ì§€ì‹ ì†Œí†µ ê³µê°„ì…ë‹ˆë‹¤. (ê¸°ë³¸ ê¸°ëŠ¥ ìœ ì§€)")
elif st.session_state.page_mode == "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ":
    st.info("í•´ê²°ì´ í•„ìš”í•œ ì§ˆë¬¸ë“¤ì´ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤. (ê¸°ë³¸ ê¸°ëŠ¥ ìœ ì§€)")
