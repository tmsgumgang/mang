import streamlit as st
from supabase import create_client, Client
import google.generativeai as genai
import pandas as pd
import PyPDF2
import io
import json
import re
import time
from collections import Counter

# [ë³´ì•ˆ] Streamlit Secrets
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)
    chat_model = genai.GenerativeModel('gemini-2.0-flash') 
    return supabase_client, chat_model

try:
    supabase, ai_model = init_clients()
except Exception as e:
    st.error(f"ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")

# --- [V124] í‘œì¤€ ì¹´í…Œê³ ë¦¬ ì •ì˜ (ê³ ì •) ---
DIRECT_INPUT_LABEL = "ì§ì ‘ ì…ë ¥"

DOMAIN_MAP = {
    "ê¸°ìˆ ì§€ì‹": {
        "ì¸¡ì •ê¸°ê¸°": ["TOC", "TN", "TP", "ì¼ë°˜í•­ëª©", "VOCs", "ë¬¼ë²¼ë£©", "í™©ì‚°í™”", "ë¯¸ìƒë¬¼", "ë°œê´‘ë°•í…Œë¦¬ì•„", "ê¸°íƒ€"],
        "ì±„ìˆ˜ì‹œì„¤": ["íŒí”„", "ë ˆë“€ìƒ¤", "í˜¸ìŠ¤", "ì»¤í”Œë§", "ìº¡ë¡", "ì—¬ê³¼ í•„í„°", "ê¸°íƒ€"],
        "ì „ì²˜ë¦¬/ë°˜ì‘ì¡°": ["ê³µí†µ"], "í†µì‹ /ë°ì´í„°": ["ê³µí†µ"], "ì „ê¸°/ì œì–´": ["ê³µí†µ"], "ì†Œëª¨í’ˆ/ì‹œì•½": ["ê³µí†µ"]
    },
    "í–‰ì •ì ˆì°¨": {
        "ì ê²€/ë³´ê³ ": ["ê³µí†µ"], "êµ¬ë§¤/ì‹ ì²­": ["ê³µí†µ"], "ì•ˆì „/ê·œì •": ["ê³µí†µ"], "ë§¤ë‰´ì–¼/ì§€ì¹¨": ["ê³µí†µ"]
    },
    "ë³µì§€ìƒí™œ": {
        "ë§›ì§‘/ì‹ë‹¹": ["ê³µí†µ"], "ì¹´í˜/í¸ì˜": ["ê³µí†µ"], "ì£¼ì°¨/êµí†µ": ["ê³µí†µ"], "ê¸°ìƒ/ì¬ë‚œ": ["ê³µí†µ"]
    }
}

# --- í•µì‹¬ í—¬í¼ í•¨ìˆ˜ ---
def clean_text_for_db(text):
    if not text: return ""
    text = text.replace("\u0000", "")
    return "".join(ch for ch in text if ch.isprintable() or ch in ['\n', '\r', '\t']).strip()

def get_embedding(text):
    clean_txt = clean_text_for_db(text)
    if not clean_txt: return [0.0] * 768
    result = genai.embed_content(model="models/text-embedding-004", content=clean_txt, task_type="retrieval_document")
    return result['embedding']

def extract_json(text):
    try:
        cleaned = re.sub(r'```json\s*|```', '', text).strip()
        return json.loads(cleaned)
    except: return None

# [V124] ê³ í’ˆì§ˆ ë§¥ë½ ë³´ì¡´ ë¶„í•  (ë³‘í•© ê¸°ì¤€ 500ìë¡œ ëŒ€í­ ê°•í™”)
def semantic_split_v124(text, target_size=1000, min_size=500):
    # ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ë’¤ì— ê³µë°±ì´ ì˜¤ëŠ” ì§€ì ì„ ìª¼ê°œê¸°
    sentences = re.split(r'(?<=[.!?])\s+', text.replace('\n', ' ').strip())
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= target_size:
            current_chunk += " " + sentence
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence
            
    # [V124 í•µì‹¬] ë§ˆì§€ë§‰ ìíˆ¬ë¦¬ ê°•ì œ ë³‘í•© ë¡œì§
    if current_chunk:
        if len(current_chunk) < min_size and chunks:
            # 500ì ë¯¸ë§Œì˜ íŒŒí¸ì€ ë¬´ì¡°ê±´ ì´ì „ ì¡°ê°ì— í•©ì¹¨ (image_ff5aa9 í˜„ìƒ ì°¨ë‹¨)
            chunks[-1] = chunks[-1] + " " + current_chunk.strip()
        else:
            chunks.append(current_chunk.strip())
            
    return chunks

def v124_route_intent(query):
    try:
        prompt = f"ì§ˆë¬¸ ë„ë©”ì¸ íŒë‹¨. [ê¸°ìˆ ì§€ì‹, í–‰ì •ì ˆì°¨, ë³µì§€ìƒí™œ] ì¤‘ í•˜ë‚˜. ì§ˆë¬¸: {query}\nJSON: {{\"domain\": \"ë„ë©”ì¸\"}}"
        res = ai_model.generate_content(prompt)
        return extract_json(res.text).get('domain', 'ê¸°ìˆ ì§€ì‹')
    except: return "ê¸°ìˆ ì§€ì‹"

# --- UI ì„¤ì • ---
st.set_page_config(page_title="ê¸ˆê°•ìˆ˜ê³„ AI ì±—ë´‡ V124", layout="centered", initial_sidebar_state="collapsed")
if 'page_mode' not in st.session_state: st.session_state.page_mode = "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰"

st.markdown("""
    <style>
    .fixed-header { position: fixed; top: 0; left: 0; width: 100%; background-color: #004a99; color: white; padding: 10px 0; z-index: 999; text-align: center; box-shadow: 0 4px 10px rgba(0,0,0,0.2); }
    .header-title { font-size: 1.1rem; font-weight: 800; }
    .main .block-container { padding-top: 4.5rem !important; }
    .meta-bar { background-color: rgba(128, 128, 128, 0.15); border-left: 5px solid #004a99; padding: 10px; border-radius: 4px; font-size: 0.85rem; margin-bottom: 12px; display: grid; grid-template-columns: repeat(auto-fit, minmax(120px, 1fr)); gap: 10px; }
    </style>
    <div class="fixed-header"><span class="header-title">ğŸŒŠ ê¸ˆê°•ìˆ˜ê³„ ìˆ˜ì§ˆìë™ì¸¡ì •ë§ AI ì±—ë´‡ V124</span></div>
    """, unsafe_allow_html=True)

menu_options = ["ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰", "ğŸ“ ì§€ì‹ ë“±ë¡", "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡", "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬", "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ", "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ"]
st.session_state.page_mode = st.selectbox("â˜° ë©”ë‰´", options=menu_options, index=menu_options.index(st.session_state.page_mode), label_visibility="collapsed")

# --- 1. í†µí•© ì§€ì‹ ê²€ìƒ‰ ---
if st.session_state.page_mode == "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰":
    search_mode = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["ì—…ë¬´ê¸°ìˆ  ğŸ› ï¸", "ìƒí™œì •ë³´ ğŸ´"], horizontal=True, label_visibility="collapsed")
    col_i, col_b = st.columns([0.8, 0.2])
    user_q = col_i.text_input("ì§ˆë¬¸ ì…ë ¥", label_visibility="collapsed", placeholder="ì¥ë¹„ ë¬¸ì œë‚˜ ë§›ì§‘ì„ ì…ë ¥í•˜ì„¸ìš”")
    if col_b.button("ì¡°íšŒ", use_container_width=True) or (user_q and len(user_q) > 1):
        if user_q:
            with st.spinner("ì „ë¬¸ ì§€ì‹ì„ í•„í„°ë§ ì¤‘..."):
                target_domain = "ë³µì§€ìƒí™œ" if "ìƒí™œì •ë³´" in search_mode else "ê¸°ìˆ ì§€ì‹"
                query_vec = get_embedding(user_q)
                exp_cands = supabase.rpc("match_knowledge", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 50}).execute().data or []
                man_cands = supabase.rpc("match_manual", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 40}).execute().data or []
                
                final_pool, seen_ks = [], set()
                for d in (exp_cands + man_cands):
                    u_key = f"{'EXP' if 'solution' in d else 'MAN'}_{d.get('id')}"
                    if (d.get('domain') == target_domain or d.get('domain') == "ê¸°ìˆ ìì‚°") and u_key not in seen_ks:
                        final_pool.append(d); seen_ks.add(u_key)

                if final_pool:
                    st.subheader("ğŸ¤– AI ì •ë°€ ìš”ì•½")
                    ans_res = ai_model.generate_content(f"ì§ˆë¬¸: {user_q} ë°ì´í„°: {final_pool[:8]}")
                    st.info(ans_res.text)
                    for i, d in enumerate(final_pool[:10]):
                        with st.expander(f"{i+1}. [{d.get('sub_category','ì¼ë°˜')}] {str(d.get('issue') or 'ë§¤ë‰´ì–¼ ì¡°ê°')[:40]}..."):
                            st.markdown(f'<div class="meta-bar"><span>ğŸ¢ ì œì¡°ì‚¬: <b>{d.get("manufacturer","ë¯¸ì§€ì •")}</b></span><span>ğŸ§ª í•­ëª©: <b>{d.get("measurement_item","ê³µí†µ")}</b></span></div>', unsafe_allow_html=True)
                            st.write(d.get('solution') or d.get('content'))
                else: st.warning("ì§€ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# --- 4. ë°ì´í„° ì „ì²´ ê´€ë¦¬ ---
elif st.session_state.page_mode == "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬":
    tabs = st.tabs(["ğŸ“ ê²½í—˜ ë¦¬íŒŒì´ë„ˆ", "ğŸ“„ ë§¤ë‰´ì–¼ ë¦¬íŒŒì´ë„ˆ", "ğŸ§¹ ì‹œë§¨í‹± ìµœì‹ í™”", "ğŸš¨ ìˆ˜ë™ ë¶„ë¥˜ì‹¤", "ğŸ—ï¸ ì§€ì‹ ì¬ê±´ì¶•"])
    
    with tabs[3]: # [V124] ìˆ˜ë™ ë¶„ë¥˜ì‹¤ (ì €ì¥ ë¡œì§ ì™„ê²°)
        st.subheader("ğŸš¨ ì§€ì‹ ìˆ˜ë™ ë¶„ë¥˜ (ì €ì¥ ê¸°ëŠ¥ ë³´ê°•)")
        t_sel = st.radio("ë¶„ë¥˜ ëŒ€ìƒ", ["ê²½í—˜", "ë§¤ë‰´ì–¼"], horizontal=True, key="rv_v124")
        t_name = "knowledge_base" if t_sel == "ê²½í—˜" else "manual_base"
        review_list = supabase.table(t_name).select("*").eq("review_required", True).limit(3).execute().data
        
        if not review_list: st.success("ğŸ‰ ëª¨ë“  ë°ì´í„°ê°€ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            for item in review_list:
                with st.container():
                    st.markdown(f"**[ë°ì´í„° ì›ë¬¸]**\n{item.get('content') or item.get('solution')}")
                    # [V124 í•µì‹¬] ì €ì¥ ì‹¤íŒ¨ ë°©ì§€ë¥¼ ìœ„í•œ í¼ êµ¬ì„±
                    with st.form(key=f"rv_form_v124_{item['id']}"):
                        c1, c2, c3 = st.columns(3)
                        # 1. ë„ë©”ì¸
                        m_dom = c1.selectbox("ë„ë©”ì¸", list(DOMAIN_MAP.keys()), key=f"dom_{item['id']}")
                        # 2. ì„¸ë¶€ë¶„ë¥˜ (ì—°ë™í˜•)
                        sub_cats = list(DOMAIN_MAP[m_dom].keys()) + [DIRECT_INPUT_LABEL]
                        m_sub_sel = c2.selectbox("ì„¸ë¶€ë¶„ë¥˜", sub_cats, key=f"sub_sel_{item['id']}")
                        m_manual_sub = c2.text_input("â”” ì„¸ë¶€ë¶„ë¥˜ ì§ì ‘ ì‘ì„±", key=f"sub_txt_{item['id']}") if m_sub_sel == DIRECT_INPUT_LABEL else ""
                        # 3. ìƒì„¸ í•­ëª© (ì—°ë™í˜•)
                        items_list = DOMAIN_MAP[m_dom].get(m_sub_sel, ["ê³µí†µ"]) if m_sub_sel != DIRECT_INPUT_LABEL else ["ê³µí†µ"]
                        m_item_sel = c3.selectbox("ìƒì„¸ í•­ëª©/ë¶€í’ˆ", items_list + [DIRECT_INPUT_LABEL], key=f"itm_sel_{item['id']}")
                        m_manual_itm = c3.text_input("â”” í•­ëª© ì§ì ‘ ì‘ì„±", key=f"itm_txt_{item['id']}") if m_item_sel == DIRECT_INPUT_LABEL else ""
                        
                        if st.form_submit_button("âœ… ë¶„ë¥˜ í™•ì • ë° ì €ì¥"):
                            # [V124 ë¡œì§] ì§ì ‘ ì…ë ¥ì°½ì˜ ê°’ì„ ìµœì¢…ì ìœ¼ë¡œ ë‚šì•„ì±„ê¸°
                            final_sub = m_manual_sub if m_sub_sel == DIRECT_INPUT_LABEL else m_sub_sel
                            final_itm = m_manual_itm if m_item_sel == DIRECT_INPUT_LABEL else m_item_sel
                            
                            if not final_sub: final_sub = "ì¼ë°˜"
                            
                            # DB ì—…ë°ì´íŠ¸
                            try:
                                supabase.table(t_name).update({
                                    "domain": m_dom,
                                    "sub_category": final_sub,
                                    "measurement_item": final_itm,
                                    "review_required": False,
                                    "semantic_version": 1
                                }).eq("id", item['id']).execute()
                                st.toast(f"ID {item['id']} ì €ì¥ ì™„ë£Œ!", icon="âœ…")
                                time.sleep(0.5); st.rerun()
                            except Exception as e:
                                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    with tabs[4]: # [V124] ì§€ì‹ ì¬ê±´ì¶• (íŒŒí¸ ë³‘í•© 500ì ê¸°ì¤€ ê°•í™”)
        st.subheader("ğŸ—ï¸ ë§¤ë‰´ì–¼ ì§€ì‹ ì¬ê±´ì¶• (ë§¥ë½ ì™„ê²° ëª¨ë“œ)")
        files = list(set([r['file_name'] for r in supabase.table("manual_base").select("file_name").execute().data if r.get('file_name')]))
        t_file = st.selectbox("ìµœì í™” ëŒ€ìƒ íŒŒì¼ ì„ íƒ", options=files)
        if st.button("ğŸš€ ë¬¸ë§¥ ë³µì› ì¬êµ¬ì„± (500ì ë¯¸ë§Œ ë³‘í•©)"):
            with st.status(f"ğŸ—ï¸ {t_file} ê³ í’ˆì§ˆ ì¬êµ¬ì„± ì¤‘...", expanded=True) as status:
                old_rows = supabase.table("manual_base").select("*").eq("file_name", t_file).order("id").execute().data
                if old_rows:
                    full_text = " ".join([r['content'] for r in old_rows])
                    new_chunks = semantic_split_v124(full_text) # V124 ê°•í™” ë¡œì§ ì ìš©
                    st.write(f"ğŸ”„ {len(old_rows)}ê°œ íŒŒí¸ â†’ {len(new_chunks)}ê°œ ê³ ë°€ë„ ë¬¸ì¥ ë©ì–´ë¦¬ë¡œ ì••ì¶•")
                    
                    for chunk in new_chunks:
                        supabase.table("manual_base").insert({
                            "domain": old_rows[0].get('domain', 'ê¸°ìˆ ì§€ì‹'),
                            "manufacturer": old_rows[0].get('manufacturer'),
                            "model_name": old_rows[0].get('model_name'),
                            "content": clean_text_for_db(chunk),
                            "file_name": t_file,
                            "embedding": get_embedding(chunk),
                            "semantic_version": 1
                        }).execute()
                    
                    # ê¸°ì¡´ íŒŒí¸ ì¼ê´„ ì‚­ì œ
                    for oid in [r['id'] for r in old_rows]: supabase.table("manual_base").delete().eq("id", oid).execute()
                    status.update(label="ì§€ì‹ ì¬ê±´ì¶• ì™„ë£Œ!", state="complete")
                    st.success("ì´ì œ íŒŒí¸ ì—†ëŠ” ì„ ëª…í•œ ì§€ì‹ìœ¼ë¡œ ê²€ìƒ‰ë©ë‹ˆë‹¤.")
                    time.sleep(1); st.rerun()

# --- 2. ì§€ì‹ ë“±ë¡ ---
elif st.session_state.page_mode == "ğŸ“ ì§€ì‹ ë“±ë¡":
    with st.form("reg_v124"):
        f_dom = st.selectbox("ë„ë©”ì¸", list(DOMAIN_MAP.keys()))
        f_mfr, f_iss, f_sol = st.text_input("ì œì¡°ì‚¬"), st.text_input("ì œëª©"), st.text_area("ë‚´ìš©")
        if st.form_submit_button("ì €ì¥"):
            supabase.table("knowledge_base").insert({"domain": f_dom, "manufacturer": f_mfr, "issue": f_iss, "solution": f_sol, "embedding": get_embedding(f_iss), "semantic_version": 1}).execute()
            st.success("ì™„ë£Œ!")

# --- 3. ë¬¸ì„œ ë“±ë¡ ---
elif st.session_state.page_mode == "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡":
    up_f = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
    if up_f:
        f_dom = st.selectbox("ë„ë©”ì¸", list(DOMAIN_MAP.keys()))
        if st.button("ğŸš€ ì§€ì‹ í•™ìŠµ ì‹œì‘ (500ì ë³‘í•© ì ìš©)"):
            up_f.seek(0)
            pdf_r = PyPDF2.PdfReader(io.BytesIO(up_f.read()))
            all_t = "\n".join([p.extract_text() for p in pdf_r.pages if p.extract_text()])
            chunks = semantic_split_v124(all_t)
            p_bar = st.progress(0)
            for i, chunk in enumerate(chunks):
                supabase.table("manual_base").insert({"domain": f_dom, "content": clean_text_for_db(chunk), "file_name": up_f.name, "embedding": get_embedding(chunk), "semantic_version": 1}).execute()
                p_bar.progress((i+1)/len(chunks))
            st.success("í•™ìŠµ ì™„ë£Œ!"); st.rerun()

elif st.session_state.page_mode == "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ":
    st.subheader("ğŸ’¬ ì†Œí†µ ê³µê°„")
elif st.session_state.page_mode == "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ":
    st.subheader("ğŸ†˜ í•´ê²°ì´ í•„ìš”í•œ ì§ˆë¬¸")
