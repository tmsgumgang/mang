import streamlit as st
from supabase import create_client, Client
import google.generativeai as genai
import pandas as pd
import PyPDF2
import io
import json
import re
import time
from collections import Counter

# [ë³´ì•ˆ] Streamlit Secrets
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)
    chat_model = genai.GenerativeModel('gemini-2.0-flash') 
    return supabase_client, chat_model

try:
    supabase, ai_model = init_clients()
except Exception as e:
    st.error(f"ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")

# --- [V129] í‘œì¤€ ì¹´í…Œê³ ë¦¬ ì •ì˜ ---
DIRECT_INPUT_LABEL = "ì§ì ‘ ì…ë ¥"
DOMAIN_MAP = {
    "ê¸°ìˆ ì§€ì‹": {
        "ì¸¡ì •ê¸°ê¸°": ["TOC", "TN", "TP", "ì¼ë°˜í•­ëª©", "VOCs", "ë¬¼ë²¼ë£©", "í™©ì‚°í™”", "ë¯¸ìƒë¬¼", "ë°œê´‘ë°•í…Œë¦¬ì•„", "ê¸°íƒ€"],
        "ì±„ìˆ˜ì‹œì„¤": ["íŒí”„", "ë ˆë“€ìƒ¤", "í˜¸ìŠ¤", "ì»¤í”Œë§", "ìº¡ë¡", "ì—¬ê³¼ í•„í„°", "ê¸°íƒ€"],
        "ì „ì²˜ë¦¬/ë°˜ì‘ì¡°": ["ê³µí†µ"], "í†µì‹ /ë°ì´í„°": ["ê³µí†µ"], "ì „ê¸°/ì œì–´": ["ê³µí†µ"], "ì†Œëª¨í’ˆ/ì‹œì•½": ["ê³µí†µ"]
    },
    "í–‰ì •ì ˆì°¨": {
        "ì ê²€/ë³´ê³ ": ["ê³µí†µ"], "êµ¬ë§¤/ì‹ ì²­": ["ê³µí†µ"], "ì•ˆì „/ê·œì •": ["ê³µí†µ"], "ë§¤ë‰´ì–¼/ì§€ì¹¨": ["ê³µí†µ"]
    },
    "ë³µì§€ìƒí™œ": {
        "ë§›ì§‘/ì‹ë‹¹": ["ê³µí†µ"], "ì¹´í˜/í¸ì˜": ["ê³µí†µ"], "ì£¼ì°¨/êµí†µ": ["ê³µí†µ"], "ê¸°ìƒ/ì¬ë‚œ": ["ê³µí†µ"]
    }
}

# --- í•µì‹¬ í—¬í¼ í•¨ìˆ˜ ---
def clean_text_for_db(text):
    if not text: return ""
    text = text.replace("\u0000", "")
    return "".join(ch for ch in text if ch.isprintable() or ch in ['\n', '\r', '\t']).strip()

def get_embedding(text):
    clean_txt = clean_text_for_db(text)
    if not clean_txt: return [0.0] * 768
    result = genai.embed_content(model="models/text-embedding-004", content=clean_txt, task_type="retrieval_document")
    return result['embedding']

def extract_json(text):
    try:
        cleaned = re.sub(r'```json\s*|```', '', text).strip()
        return json.loads(cleaned)
    except: return None

def get_penalty_counts():
    try:
        res = supabase.table("knowledge_blacklist").select("source_id").execute()
        return Counter([r['source_id'] for r in res.data])
    except: return {}

# [V129] ê³ í’ˆì§ˆ ë§¥ë½ ë³‘í•© (600ì ë¯¸ë§Œ íŒŒí¸ ê¸ˆì§€)
def semantic_split_v129(text, target_size=1200, min_size=600):
    flat_text = " ".join(text.split())
    sentences = re.split(r'(?<=[.!?])\s+', flat_text)
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= target_size:
            current_chunk += " " + sentence
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk:
        if len(current_chunk) < min_size and chunks: chunks[-1] = chunks[-1] + " " + current_chunk.strip()
        else: chunks.append(current_chunk.strip())
    return chunks

# --- UI ì„¤ì • ---
st.set_page_config(page_title="ê¸ˆê°•ìˆ˜ê³„ AI ì±—ë´‡ V129", layout="centered", initial_sidebar_state="collapsed")
if 'page_mode' not in st.session_state: st.session_state.page_mode = "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰"

st.markdown("""
    <style>
    .fixed-header { position: fixed; top: 0; left: 0; width: 100%; background-color: #004a99; color: white; padding: 10px 0; z-index: 999; text-align: center; box-shadow: 0 4px 10px rgba(0,0,0,0.2); }
    .header-title { font-size: 1.1rem; font-weight: 800; }
    .main .block-container { padding-top: 4.5rem !important; }
    .meta-bar { background-color: rgba(128, 128, 128, 0.15); border-left: 5px solid #004a99; padding: 8px; border-radius: 4px; font-size: 0.8rem; margin-bottom: 10px; display: flex; gap: 15px; }
    .guide-box { background-color: #f8fafc; border: 1px solid #e2e8f0; padding: 10px; border-radius: 6px; font-size: 0.82rem; color: #475569; margin-top: 5px; }
    </style>
    <div class="fixed-header"><span class="header-title">ğŸŒŠ ê¸ˆê°•ìˆ˜ê³„ ìˆ˜ì§ˆìë™ì¸¡ì •ë§ AI ì±—ë´‡ V129</span></div>
    """, unsafe_allow_html=True)

menu_options = ["ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰", "ğŸ“ ì§€ì‹ ë“±ë¡", "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡", "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬", "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ", "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ"]
st.session_state.page_mode = st.selectbox("â˜° ë©”ë‰´", options=menu_options, index=menu_options.index(st.session_state.page_mode), label_visibility="collapsed")

# --- 1. í†µí•© ì§€ì‹ ê²€ìƒ‰ (V129: ì‚¬ìš©ì ì •ì˜ ì„ê³„ê°’ ì œì–´) ---
if st.session_state.page_mode == "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰":
    search_mode = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["ì—…ë¬´ê¸°ìˆ  ğŸ› ï¸", "ìƒí™œì •ë³´ ğŸ´"], horizontal=True, label_visibility="collapsed")
    
    # [V129 í•µì‹¬] ê²€ìƒ‰ ì •ë°€ë„ ì œì–´ ìŠ¬ë¼ì´ë”
    with st.expander("âš™ï¸ ê²€ìƒ‰ ì •ë°€ë„ ì„¤ì • (ì„ê³„ê°’)", expanded=False):
        u_threshold = st.slider("ì„ê³„ê°’ ì¡°ì ˆ (ê°’ì´ ë†’ì„ìˆ˜ë¡ ê¹ê¹í•´ì§‘ë‹ˆë‹¤)", 0.0, 1.0, 0.5, 0.05)
        st.markdown(f"""
        <div class="guide-box">
            ğŸ¯ <b>í˜„ì¬ ëª¨ë“œ: {"ì •ë°€ íƒ€ê²© (Stricter)" if u_threshold > 0.6 else ("ê· í˜• (Balanced)" if u_threshold >= 0.4 else "í¬ê´„ íƒìƒ‰ (Broader)")}</b><br>
            â€¢ <b>ë†’ìŒ(0.7~0.9):</b> ëª¨ë¸ëª…ì´ë‚˜ ì „ë¬¸ ìš©ì–´ë¥¼ ì •í™•íˆ ì°¾ì„ ë•Œ ì¶”ì²œ<br>
            â€¢ <b>ë‚®ìŒ(0.1~0.3):</b> ì§ì ‘ì ì¸ ë‹¨ì–´ê°€ ì—†ì–´ë„ ìœ ì‚¬í•œ ë§¥ë½ì„ ì°¾ì„ ë•Œ ì¶”ì²œ
        </div>
        """, unsafe_allow_html=True)

    col_i, col_b = st.columns([0.8, 0.2])
    user_q = col_i.text_input("ì§ˆë¬¸ ì…ë ¥", label_visibility="collapsed", placeholder="ì§ˆë¬¸ì´ë‚˜ ì¥ë¹„ ëª¨ë¸ëª…ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    if col_b.button("ì¡°íšŒ", use_container_width=True) or user_q:
        if user_q:
            with st.spinner("ì„¤ì •ëœ ì •ë°€ë„ë¡œ ì§€ì‹ì„ ë¶„ì„ ì¤‘..."):
                try:
                    target_domains = ["ê¸°ìˆ ì§€ì‹", "ê¸°ìˆ ìì‚°"] if "ì—…ë¬´ê¸°ìˆ " in search_mode else ["ë³µì§€ìƒí™œ"]
                    q_vec = get_embedding(user_q)
                    penalty_map = get_penalty_counts()
                    
                    # [V129 í•µì‹¬] ì‚¬ìš©ì ì •ì˜ ì„ê³„ê°’ ì ìš©
                    m_cands = supabase.rpc("match_manual", {"query_embedding": q_vec, "match_threshold": u_threshold, "match_count": 50}).execute().data or []
                    k_cands = supabase.rpc("match_knowledge", {"query_embedding": q_vec, "match_threshold": u_threshold, "match_count": 50}).execute().data or []
                    
                    final_pool, seen_ks = [], set()
                    for d in (m_cands + k_cands):
                        u_key = f"{'EXP' if 'solution' in d else 'MAN'}_{d.get('id')}"
                        if d.get('domain') not in target_domains or d.get('review_required'): continue
                        
                        penalty = penalty_map.get(u_key, 0) * 0.05
                        d['final_score'] = (d.get('similarity') or 0) - penalty
                        if u_key not in seen_ks:
                            final_pool.append(d); seen_ks.add(u_key)

                    final_pool = sorted(final_pool, key=lambda x: x['final_score'], reverse=True)
                    
                    if final_pool:
                        st.subheader("ğŸ¤– AI ì „ë¬¸ê°€ ë¶„ì„ ìš”ì•½")
                        prompt = f"ì§ˆë¬¸: {user_q}\në°ì´í„°: {final_pool[:12]}\në„ë©”ì¸: {target_domains}. ìš”ì•½í•´ì¤˜."
                        st.info(ai_model.generate_content(prompt).text)
                        for i, d in enumerate(final_pool[:10]):
                            with st.expander(f"{i+1}. [{d.get('sub_category','ìƒì„¸ì§€ì‹')}] {str(d.get('issue') or 'ë§¤ë‰´ì–¼ ì¡°ê°')[:40]}..."):
                                st.markdown(f'<div class="meta-bar"><span>ğŸ“ ì¶œì²˜: <b>{d.get("file_name","ê°œë³„ì§€ì‹")}</b></span><span>ğŸ§ª í•­ëª©: <b>{d.get("measurement_item","ê³µí†µ")}</b></span><span>ğŸ¯ ìœ ì‚¬ë„: <b>{round(d.get("similarity",0), 2)}</b></span></div>', unsafe_allow_html=True)
                                st.write(d.get('solution') or d.get('content'))
                    else:
                        st.warning(f"ğŸ” ì„ê³„ê°’ {u_threshold} ê¸°ì¤€ìœ¼ë¡œëŠ” ì¼ì¹˜í•˜ëŠ” ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì—ì„œ ì„ê³„ê°’ì„ ë‚®ì¶”ì–´ ë³´ì„¸ìš”.")
                except Exception as e: st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

# --- 4. ë°ì´í„° ì „ì²´ ê´€ë¦¬ (ì „ ê¸°ëŠ¥ ëˆ„ë½ ì—†ìŒ) ---
elif st.session_state.page_mode == "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬":
    tabs = st.tabs(["ğŸ“ ê²½í—˜ ë¦¬íŒŒì´ë„ˆ", "ğŸ“„ ë§¤ë‰´ì–¼ ë¦¬íŒŒì´ë„ˆ", "ğŸ§¹ ì‹œë§¨í‹± ìµœì‹ í™”", "ğŸš¨ ìˆ˜ë™ ë¶„ë¥˜ì‹¤", "ğŸ—ï¸ ì§€ì‹ ì¬ê±´ì¶•"])
    
    with tabs[3]: # ìˆ˜ë™ ë¶„ë¥˜ì‹¤ (V125 ì €ì¥ ë³´ì¥ ë¡œì§)
        st.subheader("ğŸš¨ ì§€ì‹ ìˆ˜ë™ ë¶„ë¥˜ ë° ì •ë°€ íƒœê¹…")
        t_sel = st.radio("ë¶„ë¥˜ ëŒ€ìƒ", ["ê²½í—˜", "ë§¤ë‰´ì–¼"], horizontal=True, key="v129_rv")
        t_name = "knowledge_base" if t_sel == "ê²½í—˜" else "manual_base"
        review_list = supabase.table(t_name).select("*").eq("review_required", True).limit(2).execute().data
        if review_list:
            for item in review_list:
                st.markdown(f"**[ì›ë¬¸]**\n{item.get('content') or item.get('solution')}")
                with st.form(key=f"rv_v129_{item['id']}"):
                    c1, c2, c3 = st.columns(3)
                    m_dom = c1.selectbox("ë„ë©”ì¸", list(DOMAIN_MAP.keys()), key=f"d_{item['id']}")
                    m_sub_sel = c2.selectbox("ì„¸ë¶€ë¶„ë¥˜", list(DOMAIN_MAP[m_dom].keys()) + [DIRECT_INPUT_LABEL], key=f"s_{item['id']}")
                    m_sub_txt = c2.text_input("â”” ì§ì ‘ ì…ë ¥", key=f"st_{item['id']}")
                    m_itm_sel = c3.selectbox("ìƒì„¸ í•­ëª©", DOMAIN_MAP[m_dom].get(m_sub_sel, ["ê³µí†µ"]) + [DIRECT_INPUT_LABEL], key=f"i_{item['id']}")
                    m_itm_txt = c3.text_input("â”” ì§ì ‘ ì…ë ¥", key=f"it_{item['id']}")
                    if st.form_submit_button("âœ… ë¶„ë¥˜ í™•ì •"):
                        f_sub = m_sub_txt if m_sub_sel == DIRECT_INPUT_LABEL else m_sub_sel
                        f_itm = m_itm_txt if m_itm_sel == DIRECT_INPUT_LABEL else m_itm_sel
                        supabase.table(t_name).update({"domain": m_dom, "sub_category": f_sub, "measurement_item": f_itm, "review_required": False, "semantic_version": 1}).eq("id", item['id']).execute()
                        st.rerun()

    with tabs[4]: # ì§€ì‹ ì¬ê±´ì¶• (V125 ì™„ì „ ì²­ì‚° ë¡œì§)
        st.subheader("ğŸ—ï¸ ì§€ì‹ ì¬ê±´ì¶• (ë§¥ë½ ë³µì›)")
        files = sorted(list(set([r['file_name'] for r in supabase.table("manual_base").select("file_name").execute().data if r.get('file_name')])))
        t_file = st.selectbox("ìµœì í™” íŒŒì¼ ì„ íƒ", options=files)
        if st.button("ğŸš€ ì§€ì‹ ì „ë©´ ì¬êµ¬ì„±"):
            with st.status("ğŸ—ï¸ ì¬êµ¬ì„± ì¤‘...") as status:
                old_data = supabase.table("manual_base").select("*").eq("file_name", t_file).order("id").execute().data
                if old_data:
                    full_text = " ".join([r['content'] for r in old_data])
                    new_chunks = semantic_split_v129(full_text)
                    for chunk in new_chunks:
                        supabase.table("manual_base").insert({"domain": old_data[0].get('domain','ê¸°ìˆ ì§€ì‹'), "content": clean_text_for_db(chunk), "file_name": t_file, "embedding": get_embedding(chunk), "semantic_version": 1}).execute()
                    for oid in [r['id'] for r in old_data]: supabase.table("manual_base").delete().eq("id", oid).execute()
                    status.update(label="ì™„ë£Œ!", state="complete")
                st.rerun()

# --- 2, 3 ë©”ë‰´ (ì•ˆì •í™” ë¡œì§ ìœ ì§€) ---
elif st.session_state.page_mode == "ğŸ“ ì§€ì‹ ë“±ë¡":
    with st.form("reg_v129"):
        f_dom = st.selectbox("ë„ë©”ì¸", list(DOMAIN_MAP.keys()))
        f_iss, f_sol = st.text_input("ì œëª©"), st.text_area("ë‚´ìš©")
        if st.form_submit_button("ì €ì¥"):
            supabase.table("knowledge_base").insert({"domain": f_dom, "issue": f_iss, "solution": f_sol, "embedding": get_embedding(f_iss), "semantic_version": 1}).execute()
            st.success("ì™„ë£Œ!")

elif st.session_state.page_mode == "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡":
    up_f = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
    if up_f and st.button("ğŸš€ í•™ìŠµ ì‹œì‘"):
        up_f.seek(0)
        pdf_r = PyPDF2.PdfReader(io.BytesIO(up_f.read()))
        all_t = "\n".join([p.extract_text() for p in pdf_r.pages if p.extract_text()])
        chunks = semantic_split_v129(all_t)
        for chunk in chunks:
            supabase.table("manual_base").insert({"domain": "ê¸°ìˆ ì§€ì‹", "content": clean_text_for_db(chunk), "file_name": up_f.name, "embedding": get_embedding(chunk), "semantic_version": 1}).execute()
        st.success("ì™„ë£Œ!"); st.rerun()
