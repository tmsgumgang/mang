import streamlit as st
from supabase import create_client, Client
import google.generativeai as genai
import pandas as pd
import PyPDF2
import io
import json
import re
import time
from collections import Counter

# [ë³´ì•ˆ] Streamlit Secrets
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)
    chat_model = genai.GenerativeModel('gemini-2.0-flash') 
    return supabase_client, chat_model

try:
    supabase, ai_model = init_clients()
except Exception as e:
    st.error(f"ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")

# --- í•µì‹¬ í—¬í¼ í•¨ìˆ˜ ---
def keep_db_alive():
    try: supabase.table("knowledge_base").select("id").limit(1).execute()
    except: pass

def clean_text_for_db(text):
    if not text: return ""
    text = text.replace("\u0000", "")
    return "".join(ch for ch in text if ch.isprintable() or ch in ['\n', '\r', '\t']).strip()

def get_embedding(text):
    clean_txt = clean_text_for_db(text)
    if not clean_txt: return [0.0] * 768
    result = genai.embed_content(model="models/text-embedding-004", content=clean_txt, task_type="retrieval_document")
    return result['embedding']

def extract_json(text):
    try:
        cleaned = re.sub(r'```json\s*|```', '', text).strip()
        return json.loads(cleaned)
    except: return None

# [V120] ì˜ë¯¸ ì¤‘ì‹¬ í…ìŠ¤íŠ¸ ë¶„í•  (ì •ë°€í™”)
def semantic_split(text, target_size=850):
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    chunks = []
    current_chunk = ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= target_size:
            current_chunk += " " + sentence
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

def v120_route_intent(query):
    try:
        prompt = f"ì§ˆë¬¸ì˜ ë„ë©”ì¸ì„ [ê¸°ìˆ ìì‚°, í–‰ì •ì ˆì°¨, ë³µì§€ìƒí™œ] ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •í•´. ì§ˆë¬¸: {query}\nJSON: {{\"domain\": \"ë„ë©”ì¸\"}}"
        res = ai_model.generate_content(prompt)
        return extract_json(res.text).get('domain', 'ê¸°ìˆ ìì‚°')
    except: return "ê¸°ìˆ ìì‚°"

def v120_classify_data(content):
    try:
        prompt = f"ë°ì´í„° ë¶„ë¥˜. ë„ë©”ì¸:[ê¸°ìˆ ìì‚°, í–‰ì •ì ˆì°¨, ë³µì§€ìƒí™œ], ì„¸ë¶€ë¶„ë¥˜, ì¸¡ì •í•­ëª©. ë‚´ìš©: {content}\nJSON: {{\"domain\": \"ë„ë©”ì¸\", \"sub_category\": \"ë¶„ë¥˜\", \"item\": \"í•­ëª©\"}}"
        res = ai_model.generate_content(prompt)
        return extract_json(res.text)
    except: return None

# --- UI ì„¤ì • ---
st.set_page_config(page_title="ê¸ˆê°•ìˆ˜ê³„ AI ì±—ë´‡", layout="centered", initial_sidebar_state="collapsed")
keep_db_alive()
if 'page_mode' not in st.session_state: st.session_state.page_mode = "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰"

st.markdown("""
    <style>
    .fixed-header { position: fixed; top: 0; left: 0; width: 100%; background-color: #004a99; color: white; padding: 10px 0; z-index: 999; text-align: center; box-shadow: 0 4px 10px rgba(0,0,0,0.2); }
    .header-title { font-size: 1.1rem; font-weight: 800; }
    .main .block-container { padding-top: 4.5rem !important; }
    .meta-bar { background-color: rgba(128, 128, 128, 0.15); border-left: 4px solid #004a99; padding: 10px; border-radius: 4px; font-size: 0.85rem; margin-bottom: 12px; display: grid; grid-template-columns: repeat(auto-fit, minmax(120px, 1fr)); gap: 10px; }
    </style>
    <div class="fixed-header"><span class="header-title">ğŸŒŠ ê¸ˆê°•ìˆ˜ê³„ ìˆ˜ì§ˆìë™ì¸¡ì •ë§ AI ì±—ë´‡ V120</span></div>
    """, unsafe_allow_html=True)

menu_options = ["ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰", "ğŸ“ ì§€ì‹ ë“±ë¡", "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡", "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬", "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ (Q&A)", "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ"]
selected_mode = st.selectbox("â˜° ë©”ë‰´", options=menu_options, index=menu_options.index(st.session_state.page_mode), label_visibility="collapsed")
if selected_mode != st.session_state.page_mode:
    st.session_state.page_mode = selected_mode
    st.rerun()

# --- 1. í†µí•© ì§€ì‹ ê²€ìƒ‰ (V120: ì •ë°€ ê²€ìƒ‰ ìœ ì§€) ---
if st.session_state.page_mode == "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰":
    search_mode = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["ì—…ë¬´ê¸°ìˆ  ğŸ› ï¸", "ìƒí™œì •ë³´ ğŸ´"], horizontal=True, label_visibility="collapsed")
    col_i, col_b = st.columns([0.8, 0.2])
    with col_i: user_q = st.text_input("ì§ˆë¬¸ ì…ë ¥", label_visibility="collapsed", placeholder="ì¥ë¹„ ë¬¸ì œë‚˜ ë§›ì§‘ì„ ì…ë ¥í•˜ì„¸ìš”")
    with col_b: search_clicked = st.button("ì¡°íšŒ", use_container_width=True)
    
    if user_q and (search_clicked or user_q):
        with st.spinner("ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  ì§€ì‹ì„ í•„í„°ë§ ì¤‘..."):
            try:
                target_domain = "ë³µì§€ìƒí™œ" if "ìƒí™œì •ë³´" in search_mode else v120_route_intent(user_q)
                query_vec = get_embedding(user_q)
                exp_cands = supabase.rpc("match_knowledge", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 60}).execute().data or []
                man_cands = supabase.rpc("match_manual", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 40}).execute().data or []
                
                final_pool, seen_fps, seen_ks = [], set(), set()
                for d in (exp_cands + man_cands):
                    u_key = f"{'EXP' if 'solution' in d else 'MAN'}_{d.get('id')}"
                    if d.get('domain') != target_domain or d.get('review_required'): continue 
                    raw_c = d.get('solution') or d.get('content') or ""
                    f_print = "".join(raw_c.split())[:60]
                    if u_key not in seen_ks and f_print not in seen_fps:
                        d['final_score'] = d.get('similarity') or 0
                        final_pool.append(d); seen_ks.add(u_key); seen_fps.add(f_print)

                final_pool = sorted(final_pool, key=lambda x: x['final_score'], reverse=True)
                if final_pool:
                    st.subheader("ğŸ¤– AI ì •ë°€ ìš”ì•½")
                    ans_res = ai_model.generate_content(f"ì§ˆë¬¸: {user_q} ë°ì´í„°: {final_pool[:12]}")
                    st.info(ans_res.text)
                    for i, d in enumerate(final_pool[:10]):
                        with st.expander(f"{i+1}. [{d.get('domain')}] {str(d.get('issue') or 'ìƒì„¸ë‚´ìš©')[:40]}..."):
                            st.write(d.get('solution') or d.get('content'))
                else: st.warning("ì§€ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e: st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {e}")

# --- 4. ë°ì´í„° ì „ì²´ ê´€ë¦¬ (V120: ì§€ì‹ ì¬ê±´ì¶• ë©”ë‰´ ì¶”ê°€) ---
elif st.session_state.page_mode == "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬":
    tabs = st.tabs(["ğŸ“Š ë¡œê·¸ ë¶„ì„", "ğŸ“ ê²½í—˜ ë¦¬íŒŒì´ë„ˆ", "ğŸ“„ ë§¤ë‰´ì–¼ ë¦¬íŒŒì´ë„ˆ", "ğŸš« êµì • ê¸°ë¡", "ğŸ§¹ ì‹œë§¨í‹± ìµœì‹ í™”", "ğŸš¨ ìˆ˜ë™ ë¶„ë¥˜ì‹¤", "ğŸ—ï¸ ì§€ì‹ ì¬ê±´ì¶•"])
    
    with tabs[6]: # [V120 í•µì‹¬] ì§€ì‹ ì¬ê±´ì¶•
        st.subheader("ğŸ—ï¸ ê¸°ì¡´ ë§¤ë‰´ì–¼ ì§€ì‹ ì¬ê±´ì¶• (ìµœì í™”)")
        st.write("ëšëš ëŠê²¨ìˆëŠ” ê¸°ì¡´ PDF ì¡°ê°ë“¤ì„ íŒŒì¼ ë‹¨ìœ„ë¡œ í•©ì¹œ ë’¤, ë¬¸ë§¥ì´ ë³´ì¡´ë˜ë„ë¡ ë‹¤ì‹œ ë‚˜ëˆ•ë‹ˆë‹¤.")
        
        # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        files_res = supabase.table("manual_base").select("file_name").execute()
        file_list = sorted(list(set([r['file_name'] for r in files_res.data if r.get('file_name')])))
        target_file = st.selectbox("ì¬ê±´ì¶• ëŒ€ìƒ íŒŒì¼ ì„ íƒ", options=file_list)
        
        if st.button("ğŸš€ ì„ íƒí•œ íŒŒì¼ ìµœì í™” ì‹œì‘"):
            with st.status(f"ğŸ—ï¸ {target_file} ì¬êµ¬ì„± ì¤‘...", expanded=True) as status:
                # 1. ê¸°ì¡´ íŒŒí¸ ë¶ˆëŸ¬ì˜¤ê¸°
                old_rows = supabase.table("manual_base").select("*").eq("file_name", target_file).order("id").execute().data
                if old_rows:
                    full_text = " ".join([r['content'] for r in old_rows])
                    domain_info = old_rows[0].get('domain', 'ê¸°ìˆ ìì‚°')
                    mfr_info = old_rows[0].get('manufacturer', 'ê¸°íƒ€')
                    model_info = old_rows[0].get('model_name', 'ë§¤ë‰´ì–¼')
                    
                    # 2. ì˜ë¯¸ ì¤‘ì‹¬ ì¬ë¶„í• 
                    new_chunks = semantic_split(full_text)
                    st.write(f"ğŸ”„ {len(old_rows)}ê°œ íŒŒí¸ â†’ {len(new_chunks)}ê°œ ì˜ë¯¸ ë©ì–´ë¦¬ë¡œ ì¬êµ¬ì„±")
                    
                    # 3. ìƒˆë¡œìš´ ì¡°ê° ì €ì¥
                    for chunk in new_chunks:
                        supabase.table("manual_base").insert({
                            "domain": domain_info, "manufacturer": mfr_info, "model_name": model_info,
                            "content": clean_text_for_db(chunk), "file_name": target_file,
                            "embedding": get_embedding(chunk), "semantic_version": 1
                        }).execute()
                    
                    # 4. ì´ì „ íŒŒí¸ ì‚­ì œ (ID ê¸°ë°˜)
                    old_ids = [r['id'] for r in old_rows]
                    for oid in old_ids:
                        supabase.table("manual_base").delete().eq("id", oid).execute()
                        
                    status.update(label="ì§€ì‹ ì¬ê±´ì¶• ì™„ë£Œ!", state="complete")
                    st.success("ì´ì œ ë¬¸ë§¥ì´ ëŠê¸°ì§€ ì•ŠëŠ” ìµœì í™”ëœ ìƒíƒœë¡œ ê²€ìƒ‰ë©ë‹ˆë‹¤.")
                    time.sleep(1); st.rerun()

    with tabs[5]: # ìˆ˜ë™ ë¶„ë¥˜ ëŒ€ê¸°ì‹¤ (V119 UI ìœ ì§€)
        st.subheader("ğŸš¨ ìˆ˜ë™ ë¶„ë¥˜ ëŒ€ê¸°ì‹¤")
        t_sel = st.radio("í…Œì´ë¸”", ["ê²½í—˜", "ë§¤ë‰´ì–¼"], horizontal=True, key="rv_target")
        t_name = "knowledge_base" if t_sel == "ê²½í—˜" else "manual_base"
        existing_data = supabase.table(t_name).select("sub_category").execute().data
        cat_options = sorted(list(set([r['sub_category'] for r in existing_data if r.get('sub_category')]))) + ["ì§ì ‘ ì…ë ¥"]
        
        review_list = supabase.table(t_name).select("*").eq("review_required", True).limit(5).execute().data
        if not review_list: st.success("ğŸ‰ ê²€í† í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        else:
            for item in review_list:
                with st.container():
                    st.markdown(f"**[ë°ì´í„° ì›ë¬¸]**\n{item.get('issue') or ''}\n{item.get('solution') or item.get('content', '')}")
                    with st.form(key=f"rv_form_{t_name}_{item['id']}"):
                        c1, c2, c3 = st.columns(3)
                        m_dom = c1.selectbox("ë„ë©”ì¸", ["ê¸°ìˆ ìì‚°", "í–‰ì •ì ˆì°¨", "ë³µì§€ìƒí™œ"])
                        m_sub_sel = c2.selectbox("ë¶„ë¥˜", options=cat_options, key=f"sel_{item['id']}")
                        m_sub_manual = c2.text_input("â”” ì§ì ‘ ì…ë ¥", key=f"inp_{item['id']}") if m_sub_sel == "ì§ì ‘ ì…ë ¥" else ""
                        m_item = c3.text_input("í•­ëª©", value=item.get('measurement_item', 'ê³µí†µ'))
                        if st.form_submit_button("âœ… ë¶„ë¥˜ í™•ì •"):
                            final_sub = m_sub_manual if m_sub_sel == "ì§ì ‘ ì…ë ¥" else m_sub_sel
                            supabase.table(t_name).update({"domain": m_dom, "sub_category": final_sub, "measurement_item": m_item, "review_required": False}).eq("id", item['id']).execute()
                            st.rerun()
                st.divider()

# --- 2, 3, 5, 6 ë©”ë‰´ (ë¡œì§ ìœ ì§€) ---
elif st.session_state.page_mode == "ğŸ“ ì§€ì‹ ë“±ë¡":
    st.subheader("ğŸ“ ì‹ ê·œ ì§€ì‹ ë“±ë¡")
    with st.form("reg_v120", clear_on_submit=True):
        f_dom = st.selectbox("ë„ë©”ì¸", ["ê¸°ìˆ ìì‚°", "í–‰ì •ì ˆì°¨", "ë³µì§€ìƒí™œ"])
        f_mfr, f_iss, f_sol = st.text_input("ì œì¡°ì‚¬"), st.text_input("ì œëª©"), st.text_area("ë‚´ìš©")
        if st.form_submit_button("ì €ì¥"):
            supabase.table("knowledge_base").insert({"domain": f_dom, "manufacturer": f_mfr, "issue": f_iss, "solution": f_sol, "embedding": get_embedding(f"{f_dom} {f_mfr} {f_iss}"), "semantic_version": 1}).execute()
            st.success("ì €ì¥ ì™„ë£Œ!")

elif st.session_state.page_mode == "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡":
    st.subheader("ğŸ“„ ë§¤ë‰´ì–¼ ë“±ë¡ (ì˜ë¯¸ ì¤‘ì‹¬ ë¶„í• )")
    up_f = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
    if up_f:
        f_dom = st.selectbox("ë¬¸ì„œ ë„ë©”ì¸", ["ê¸°ìˆ ìì‚°", "í–‰ì •ì ˆì°¨", "ë³µì§€ìƒí™œ"])
        if st.button("ğŸš€ í•™ìŠµ ì‹œì‘"):
            up_f.seek(0)
            pdf_r = PyPDF2.PdfReader(io.BytesIO(up_f.read()))
            all_t = "\n".join([p.extract_text() for p in pdf_r.pages if p.extract_text()])
            chunks = semantic_split(all_t)
            p_bar = st.progress(0)
            for i, chunk in enumerate(chunks):
                supabase.table("manual_base").insert({"domain": f_dom, "content": clean_text_for_db(chunk), "file_name": up_f.name, "embedding": get_embedding(chunk), "semantic_version": 1}).execute()
                p_bar.progress((i+1)/len(chunks))
            st.success("í•™ìŠµ ì™„ë£Œ!"); st.rerun()

elif st.session_state.page_mode == "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ (Q&A)":
    st.subheader("ğŸ’¬ ì†Œí†µ ê³µê°„") # ê¸°ë³¸ ë¡œì§ ìœ ì§€
elif st.session_state.page_mode == "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ":
    st.subheader("ğŸ†˜ í•´ê²°ì´ í•„ìš”í•œ ì§ˆë¬¸") # ê¸°ë³¸ ë¡œì§ ìœ ì§€
