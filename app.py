import streamlit as st
from supabase import create_client, Client
import google.generativeai as genai

# [ë³´ì•ˆ] Streamlit Secrets ì—°ë™
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. Settings > Secretsë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    st.stop()

@st.cache_resource
def init_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)
    # Gemini 2.0 Flash ëª¨ë¸ ì„¤ì •
    chat_model = genai.GenerativeModel('gemini-2.0-flash') 
    return supabase_client, chat_model

try:
    supabase, ai_model = init_clients()
except Exception as e:
    st.error(f"ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")

# ë²¡í„° ì„ë² ë”© ìƒì„± í•¨ìˆ˜ (768ì°¨ì›)
def get_embedding(text):
    result = genai.embed_content(
        model="models/text-embedding-004",
        content=text,
        task_type="retrieval_document"
    )
    return result['embedding']

# --- ëª¨ë°”ì¼ ë° ì›¹ ìµœì í™” UI ---
st.set_page_config(
    page_title="K-eco ì¡°ì¹˜ë´‡", 
    layout="centered", 
    initial_sidebar_state="collapsed",
    page_icon="ğŸŒŠ"
)

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("âš™ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬")
mode = st.sidebar.radio("ì‘ì—… ì„ íƒ", ["ğŸ¤– ê²€ì¦ ì§€ì‹ ì¡°ì¹˜ ê°€ì´ë“œ", "ğŸ“ ìƒˆë¡œìš´ ì‚¬ë¡€ ë“±ë¡", "ğŸ› ï¸ ë°ì´í„° ì§„ë‹¨"])
search_threshold = st.sidebar.slider("ê²€ìƒ‰ ì •ë°€ë„ (Threshold)", 0.0, 1.0, 0.35, 0.05)

st.title("ğŸŒŠ K-eco í˜„ì¥ ì¡°ì¹˜ ì±—ë´‡")
st.caption("ì„±ì£¼ ë‹˜ì˜ DB ì‚¬ë¡€ë§Œ 'ê·¸ëŒ€ë¡œ' ì „ë‹¬í•˜ëŠ” ìš¸íŠ¸ë¼ ì—„ê²© ëª¨ë“œì…ë‹ˆë‹¤.")
st.markdown("---")

# --- ê¸°ëŠ¥ 1: ì§€ëŠ¥í˜• ì¡°ì¹˜ ê°€ì´ë“œ (Ultra-Strict Mode) ---
if mode == "ğŸ¤– ê²€ì¦ ì§€ì‹ ì¡°ì¹˜ ê°€ì´ë“œ":
    st.subheader("ğŸ“± í˜„ì¥ ìƒí™© ì„¤ëª…")
    user_question = st.text_input("", placeholder="ì˜ˆ: ì‹œë§ˆì¦ˆ TOC-4200 í—ŒíŒ… ë°œìƒ")
    
    if user_question:
        with st.spinner("DBì—ì„œ ì„±ì£¼ ë‹˜ì˜ ë…¸í•˜ìš°ë¥¼ ê¸°ê³„ì ìœ¼ë¡œ ì¶”ì¶œ ì¤‘..."):
            try:
                # 1. ì§ˆë¬¸ ë²¡í„°í™”
                query_vec = get_embedding(user_question)
                
                # 2. ë²¡í„° ê²€ìƒ‰ í˜¸ì¶œ (ìœ ì‚¬ë„ ë†’ì€ 2ê°œë§Œ ì¶”ì¶œ)
                rpc_res = supabase.rpc("match_knowledge", {
                    "query_embedding": query_vec,
                    "match_threshold": search_threshold,
                    "match_count": 2
                }).execute()
                
                past_cases = rpc_res.data
                
                if past_cases:
                    # AIì—ê²Œ ì¤„ ì»¨í…ìŠ¤íŠ¸ ë° ì¶œì²˜ êµ¬ì„±
                    context_data = ""
                    source_names = []
                    for i, c in enumerate(past_cases):
                        context_data += f"### ë°ì´í„° {i+1}\n- ì¥ë¹„ëª…: {c['equipment']}\n- ë°œìƒí˜„ìƒ: {c['issue']}\n- í•´ê²°ë°©ë²•: {c['solution']}\n\n"
                        source_names.append(f"{c['equipment']} (ID: {c.get('id', 'N/A')})")

                    # [ì ˆëŒ€ ê·œì¹™] ì°½ì˜ì„±ì„ 0ìœ¼ë¡œ ë§Œë“¤ê³  ì™¸ë¶€ ì§€ì‹ì„ ì™„ì „íˆ ì°¨ë‹¨í•˜ëŠ” ì„¤ì •
                    generation_config = {
                        "temperature": 0.0, # ìƒìƒë ¥ ì™„ì „ ì œê±°
                        "top_p": 1,
                        "top_k": 1,
                        "max_output_tokens": 800,
                    }

                    # í”„ë¡¬í”„íŠ¸ì˜ ëª…ë ¹ ê°•ë„ë¥¼ 'ê²½ê³ ' ìˆ˜ì¤€ìœ¼ë¡œ ìƒí–¥
                    prompt = f"""
                    [ê²½ê³ : ë‹¹ì‹ ì˜ ì§€ì‹ì€ ëª¨ë‘ ë¬´ì‹œí•˜ì‹­ì‹œì˜¤]
                    ë‹¹ì‹ ì€ ìˆ˜ì§ˆ ì „ë¬¸ê°€ê°€ ì•„ë‹™ë‹ˆë‹¤. ì•„ë˜ [ì œê³µëœ ë°ì´í„°]ì— ì íŒ 'í•´ê²°ë°©ë²•' í…ìŠ¤íŠ¸ë¥¼ ì„±ì£¼ ë‹˜ì—ê²Œ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ê¸°ê³„ì…ë‹ˆë‹¤. 
                    
                    [ì‘ì„± ìˆ˜ì¹™ - ì–´ê¸¸ ì‹œ ë‹µë³€ ë¬´íš¨]
                    1. ì²« ë¬¸ì¥ì€ ë¬´ì¡°ê±´ "ì„±ì£¼ ë‹˜ì˜ {', '.join(source_names)} ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤."ë¡œ ì‹œì‘í•˜ì‹­ì‹œì˜¤.
                    2. ì˜¤ì§ [ì œê³µëœ ë°ì´í„°]ì˜ 'í•´ê²°ë°©ë²•'ì— ì íŒ í…ìŠ¤íŠ¸ë§Œ ìš”ì•½í•˜ì‹­ì‹œì˜¤.
                    3. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©(NDIR, ì‹œì•½ ìœ íš¨ê¸°ê°„, íŒí”„ íŠœë¸Œ, ì‹¤í—˜ì‹¤ í™˜ê²½ ë“±)ì„ ë‹¨ í•œ ê¸€ìë¼ë„ ì–¸ê¸‰í•˜ë©´ ë‹¹ì‹ ì€ ì‹¤íŒ¨í•œ ê²ƒì…ë‹ˆë‹¤.
                    4. "ë§¤ë‰´ì–¼ì„ ë´ë¼", "ì£¼ì˜ì‚¬í•­" ê°™ì€ ì‚¬ì¡±ì€ ì ˆëŒ€ë¡œ ë¶™ì´ì§€ ë§ˆì‹­ì‹œì˜¤.
                    5. ë°ì´í„°ê°€ ì§ˆë¬¸ê³¼ ì¡°ê¸ˆì´ë¼ë„ ë‹¤ë¥´ë©´ ë‹µë³€í•˜ì§€ ë§ê³  "ìœ ì‚¬í•œ ì‚¬ë¡€ê°€ ê²€ìƒ‰ë˜ì—ˆìœ¼ë‚˜ ì¡°ì¹˜ ë°©ë²•ì€ ì§ì ‘ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."ë¼ê³ ë§Œ í•˜ì‹­ì‹œì˜¤.

                    [ì œê³µëœ ë°ì´í„°]
                    {context_data}
                    
                    [ì‚¬ìš©ì ì§ˆë¬¸]
                    {user_question}
                    """
                    
                    response = ai_model.generate_content(
                        prompt,
                        generation_config=generation_config
                    )
                    
                    st.markdown("### ğŸ’¡ ê²€ì¦ëœ ì¡°ì¹˜ ì‚¬í•­")
                    # ë‹µë³€ì„ ê°•ì¡° ë°•ìŠ¤ì— í‘œì‹œí•˜ì—¬ ê°€ì‹œì„± í™•ë³´
                    st.success(response.text)
                    
                    with st.expander("ğŸ“š ì°¸ì¡°í•œ ì‹¤ì œ DB ë ˆì½”ë“œ"):
                        st.table(past_cases)
                else:
                    st.warning("âš ï¸ í˜„ì¬ DBì— ì„±ì£¼ ë‹˜ì´ ë“±ë¡í•˜ì‹  ìœ ì‚¬ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê°ë„ë¥¼ ë‚®ì¶”ê±°ë‚˜ ì‚¬ë¡€ë¥¼ ë¨¼ì € ë“±ë¡í•´ ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

# --- ê¸°ëŠ¥ 2: ìƒˆë¡œìš´ ì‚¬ë¡€ ë“±ë¡ (ìë™ ë²¡í„°í™” í¬í•¨) ---
elif mode == "ğŸ“ ìƒˆë¡œìš´ ì‚¬ë¡€ ë“±ë¡":
    st.subheader("ğŸ“ ì‹ ê·œ ë…¸í•˜ìš° ë“±ë¡")
    st.info("ì´ê³³ì— ì €ì¥í•˜ëŠ” ëª¨ë“  ë°ì´í„°ëŠ” AIì— ì˜í•´ ìë™ìœ¼ë¡œ ì‹¤ì‹œê°„ ë²¡í„°í™”ë©ë‹ˆë‹¤.")
    with st.form("add_form", clear_on_submit=True):
        eq = st.selectbox("ì¥ë¹„", ["ì‹œë§ˆì¦ˆ TOC-4200", "Robochem A2", "HATP-2000", "KORBI TN/TP", "ê¸°íƒ€"])
        iss = st.text_input("í˜„ìƒ (ì˜ˆ: ì¸¡ì •ê°’ ê¸‰ìƒìŠ¹)")
        sol = st.text_area("ì¡°ì¹˜ ë‚´ìš© (ì„±ì£¼ ë‹˜ë§Œì˜ í•´ê²° ë°©ë²•)")
        
        if st.form_submit_button("ì§€ì‹ ë² ì´ìŠ¤ ì €ì¥"):
            if eq and iss and sol:
                with st.spinner("AI ë¶„ì„ ë° ìë™ ë²¡í„°í™” ì¤‘..."):
                    # ì €ì¥ ì‹œì ì— ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ í•¨ê»˜ ì €ì¥
                    vec = get_embedding(f"ì¥ë¹„:{eq} í˜„ìƒ:{iss} ì¡°ì¹˜:{sol}")
                    supabase.table("knowledge_base").insert({
                        "equipment": eq, "issue": iss, "solution": sol, "embedding": vec
                    }).execute()
                    st.success("âœ… ì§€ì‹ì´ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ê¸°ëŠ¥ 3: ë°ì´í„° ì§„ë‹¨ ---
elif mode == "ğŸ› ï¸ ë°ì´í„° ì§„ë‹¨":
    st.subheader("ğŸ› ï¸ ë°ì´í„° ìƒíƒœ ì§„ë‹¨")
    res = supabase.table("knowledge_base").select("id, equipment, issue, embedding").execute()
    if res.data:
        missing = [i for i in res.data if i.get('embedding') is None]
        st.write(f"ì „ì²´ ì§€ì‹ ìˆ˜: {len(res.data)}ê±´")
        if missing:
            st.warning(f"ë²¡í„° ë°ì´í„°(ì§€ëŠ¥)ê°€ ëˆ„ë½ëœ ê³¼ê±° ë°ì´í„°: {len(missing)}ê±´")
            if st.button("ğŸ”„ ëˆ„ë½ ë°ì´í„° ì¼ê´„ ë³µêµ¬"):
                for item in missing:
                    vec = get_embedding(f"ì¥ë¹„:{item['equipment']} í˜„ìƒ:{item['issue']}")
                    supabase.table("knowledge_base").update({"embedding": vec}).eq("id", item['id']).execute()
                st.success("ë³µêµ¬ ì™„ë£Œ!")
                st.rerun()
        else:
            st.success("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì •ìƒì ìœ¼ë¡œ ë²¡í„°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
