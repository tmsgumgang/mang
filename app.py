import streamlit as st
from supabase import create_client, Client
import google.generativeai as genai
import pandas as pd
import PyPDF2
import io
import json
import re
import time
from collections import Counter

# [ë³´ì•ˆ] Streamlit Secrets
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)
    chat_model = genai.GenerativeModel('gemini-2.0-flash') 
    return supabase_client, chat_model

try:
    supabase, ai_model = init_clients()
except Exception as e:
    st.error(f"ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")

# --- í•µì‹¬ í—¬í¼ í•¨ìˆ˜ ---
def keep_db_alive():
    try: supabase.table("knowledge_base").select("id").limit(1).execute()
    except: pass

def clean_text_for_db(text):
    if not text: return ""
    text = text.replace("\u0000", "")
    return "".join(ch for ch in text if ch.isprintable() or ch in ['\n', '\r', '\t']).strip()

def get_embedding(text):
    clean_txt = clean_text_for_db(text)
    if not clean_txt: return [0.0] * 768
    result = genai.embed_content(model="models/text-embedding-004", content=clean_txt, task_type="retrieval_document")
    return result['embedding']

def extract_json(text):
    try:
        cleaned = re.sub(r'```json\s*|```', '', text).strip()
        return json.loads(cleaned)
    except: return None

def log_unsolved(query, reason, is_life):
    try:
        exists = supabase.table("unsolved_questions").select("id").eq("query", query).eq("status", "ëŒ€ê¸°ì¤‘").execute().data
        if not exists:
            supabase.table("unsolved_questions").insert({"query": query, "reason": reason, "is_lifestyle": is_life}).execute()
    except: pass

def get_penalty_counts():
    try:
        res = supabase.table("knowledge_blacklist").select("source_id").execute()
        return Counter([r['source_id'] for r in res.data])
    except: return {}

# [V113] ì§€ëŠ¥í˜• ë¶„ë¥˜ ë° ëª…ì°° ì‹œìŠ¤í…œ
def display_tag_v113(u_key, domain):
    prefix = "ê²½í—˜ì§€ì‹" if "EXP" in u_key else "ë§¤ë‰´ì–¼"
    icon = "ğŸ› ï¸" if domain == "ê¸°ìˆ ìì‚°" else ("ğŸ´" if domain == "ë³µì§€ìƒí™œ" else "ğŸ“‹")
    return f"{icon} {prefix}_{u_key.split('_')[1]} ({domain})"

def analyze_domain_v113(text):
    if not text: return "ê¸°ìˆ ìì‚°"
    life_keys = ["ë§›ì§‘", "ì‹ë‹¹", "ì¹´í˜", "ì¶”ì²œ", "ì£¼ì°¨", "ì ì‹¬", "ì €ë…", "íšŒì‹", "ë©”ë‰´", "ì§œê¸€ì´"]
    admin_keys = ["ì¼ì§€", "ì–‘ì‹", "ë³´ê³ ì„œ", "ì‹ ì²­", "ì ˆì°¨", "ì•ˆì „", "ê·œì¹™", "ê³µë¬¸"]
    if any(k in text for k in life_keys): return "ë³µì§€ìƒí™œ"
    if any(k in text for k in admin_keys): return "í–‰ì •ì ˆì°¨"
    return "ê¸°ìˆ ìì‚°"

# [V113 í•µì‹¬] ë§ˆì´ê·¸ë ˆì´ì…˜ AI ì—ì´ì „íŠ¸ (ì—ëŸ¬ ë°©ì–´ ë¡œì§ ê°•í™”)
def ai_classify_data(content):
    try:
        prompt = f"""ì•„ë˜ ë°ì´í„°ë¥¼ [ë„ë©”ì¸ / ì„¸ë¶€ë¶„ë¥˜ / ì¸¡ì •í•­ëª©]ìœ¼ë¡œ ë¶„ë¥˜í•´ì„œ JSONìœ¼ë¡œë§Œ ëŒ€ë‹µí•´.
        ë„ë©”ì¸: [ê¸°ìˆ ìì‚°, í–‰ì •ì ˆì°¨, ë³µì§€ìƒí™œ] ì¤‘ í•˜ë‚˜
        ë°ì´í„°: {content}
        ì‘ë‹µì˜ˆì‹œ: {{"domain": "ê¸°ìˆ ìì‚°", "sub_category": "ì¸¡ì •ê¸°ê¸°", "item": "TOC"}}"""
        res = ai_model.generate_content(prompt)
        parsed = extract_json(res.text)
        return parsed if isinstance(parsed, dict) else None
    except: return None

def get_blacklist(query):
    try:
        res = supabase.table("knowledge_blacklist").select("source_id").eq("query", query).execute()
        return [r['source_id'] for r in res.data]
    except: return []

# --- UI ì„¤ì • ---
st.set_page_config(page_title="ê¸ˆê°•ìˆ˜ê³„ AI ì±—ë´‡", layout="centered", initial_sidebar_state="collapsed")
keep_db_alive()
if 'page_mode' not in st.session_state: st.session_state.page_mode = "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰"

st.markdown("""
    <style>
    .fixed-header { position: fixed; top: 0; left: 0; width: 100%; background-color: #004a99; color: white; padding: 10px 0; z-index: 999; text-align: center; box-shadow: 0 4px 10px rgba(0,0,0,0.2); }
    .header-title { font-size: 1.1rem; font-weight: 800; }
    .main .block-container { padding-top: 4.5rem !important; }
    .guide-box { background-color: rgba(240, 253, 244, 0.1); border: 1px solid #bbf7d0; padding: 12px; border-radius: 8px; font-size: 0.85rem; margin-bottom: 15px; color: #166534; }
    .meta-bar { background-color: rgba(128, 128, 128, 0.15); border-left: 5px solid #004a99; padding: 10px; border-radius: 4px; font-size: 0.85rem; margin-bottom: 12px; display: grid; grid-template-columns: repeat(auto-fit, minmax(120px, 1fr)); gap: 10px; }
    </style>
    <div class="fixed-header"><span class="header-title">ğŸŒŠ ê¸ˆê°•ìˆ˜ê³„ ìˆ˜ì§ˆìë™ì¸¡ì •ë§ AI ì±—ë´‡ V113</span></div>
    """, unsafe_allow_html=True)

menu_options = ["ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰", "ğŸ“ ì§€ì‹ ë“±ë¡", "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡", "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬", "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ (Q&A)", "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ"]
selected_mode = st.selectbox("â˜° ë©”ë‰´", options=menu_options, index=menu_options.index(st.session_state.page_mode), label_visibility="collapsed")
if selected_mode != st.session_state.page_mode:
    st.session_state.page_mode = selected_mode
    st.rerun()

# --- 1. í†µí•© ì§€ì‹ ê²€ìƒ‰ (ë„ë©”ì¸ ê²©ë¦¬ ì—”ì§„) ---
if st.session_state.page_mode == "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰":
    search_mode = st.radio("ê²€ìƒ‰ ë„ë©”ì¸", ["ì—…ë¬´ê¸°ìˆ  ğŸ› ï¸", "ìƒí™œì •ë³´ ğŸ´"], horizontal=True, label_visibility="collapsed")
    col_i, col_b = st.columns([0.8, 0.2])
    with col_i: user_q = st.text_input("ì§ˆë¬¸ ì…ë ¥", label_visibility="collapsed", placeholder="ì¥ë¹„ ë¬¸ì œë‚˜ ë§›ì§‘ì„ ì…ë ¥í•˜ì„¸ìš”")
    with col_b: search_clicked = st.button("ì¡°íšŒ", use_container_width=True)
    
    if user_q and (search_clicked or user_q):
        with st.spinner("ë„ë©”ì¸ ë¶„ì„ ë° ì§€ì‹ ê²©ë¦¬ ì¤‘..."):
            try:
                target_domain = "ë³µì§€ìƒí™œ" if "ìƒí™œì •ë³´" in search_mode else analyze_domain_v113(user_q)
                query_vec = get_embedding(user_q)
                blacklist_ids = get_blacklist(user_q)
                penalty_map = get_penalty_counts()
                
                exp_cands = supabase.rpc("match_knowledge", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 60}).execute().data or []
                man_cands = supabase.rpc("match_manual", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 40}).execute().data or []
                
                final_pool, seen_fps, seen_ks = [], set(), set()
                for d in (exp_cands + man_cands):
                    u_key = f"{'EXP' if 'solution' in d else 'MAN'}_{d.get('id')}"
                    if u_key in blacklist_ids: continue
                    
                    # [V113] ë„ë©”ì¸ ë§¤ì¹­ (ë¬¼ë¦¬ì  ê²©ë¦¬)
                    d_dom = d.get('domain') or analyze_domain_v113(str(d.get('issue') or d.get('content')))
                    if target_domain != d_dom: continue
                    
                    penalty = penalty_map.get(u_key, 0) * 0.05
                    bonus = 0.5 if target_domain == "ê¸°ìˆ ìì‚°" and any(k in str(d.get('manufacturer','')).lower() for k in ["ì‹œë§ˆì¦ˆ", "ë°±ë…„ê¸°ìˆ "]) else 0
                    
                    raw_c = d.get('solution') or d.get('content') or ""
                    f_print = "".join(raw_c.split())[:60]
                    if u_key not in seen_ks and f_print not in seen_fps:
                        d['final_score'] = (d.get('similarity') or 0) + bonus - penalty
                        d['source_id_tag'], d['final_dom'] = u_key, d_dom
                        final_pool.append(d); seen_ks.add(u_key); seen_fps.add(f_print)

                final_pool = sorted(final_pool, key=lambda x: x['final_score'], reverse=True)
                if final_pool:
                    st.subheader("ğŸ¤– AI ì •ë°€ ìš”ì•½")
                    context = "\n".join([f"[{d['source_id_tag']}]: {d.get('solution') or d.get('content')}" for d in final_pool[:12]])
                    ans_p = f"ìˆ˜ì§ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë„ë©”ì¸: {target_domain}. ì§ˆë¬¸: {user_q} \n ë°ì´í„°: {context} \n ìš”ì•½ í›„ ì¶œì²˜ í‘œê¸°."
                    st.info(ai_model.generate_content(ans_p).text)
                    
                    for i, d in enumerate(final_pool[:10]):
                        with st.expander(f"{i+1}. [{d['final_dom']}] {str(d.get('issue') or 'ìƒì„¸ ë‚´ìš©')[:35]}..."):
                            st.markdown(f"""<div class="meta-bar">
                                <div>ğŸ¢ ì œì¡°ì‚¬: <b>{d.get('manufacturer', 'ë¯¸ì§€ì •')}</b></div>
                                <div>ğŸ·ï¸ ëª¨ë¸: <b>{d.get('model_name', 'ë¯¸ì§€ì •')}</b></div>
                                <div>ğŸ§ª í•­ëª©: <b>{d.get('measurement_item', 'ê³µí†µ')}</b></div>
                            </div>""", unsafe_allow_html=True)
                            st.write(d.get('solution') or d.get('content'))
                            c1, c2 = st.columns(2)
                            if c1.button("ğŸ‘ ë„ì›€ë¨", key=f"ok_{d['source_id_tag']}"):
                                table = "knowledge_base" if "EXP" in d['source_id_tag'] else "manual_base"
                                supabase.table(table).update({"helpful_count": (d.get('helpful_count') or 0)+1}).eq("id", int(d['source_id_tag'].split('_')[1])).execute()
                                st.success("ì¶”ì²œ ì™„ë£Œ!"); st.rerun()
                            with c2:
                                with st.popover("âŒ êµì •/ì œì™¸", use_container_width=True):
                                    fix_cat = st.selectbox("ë¶„ë¥˜ êµì •", ["ê¸°ìˆ ìì‚°", "í–‰ì •ì ˆì°¨", "ë³µì§€ìƒí™œ"], key=f"fix_{d['source_id_tag']}")
                                    if st.button("êµì • ë° ì œì™¸", key=f"btn_{d['source_id_tag']}", type="primary"):
                                        table = "knowledge_base" if "EXP" in d['source_id_tag'] else "manual_base"
                                        supabase.table(table).update({"domain": fix_cat}).eq("id", int(d['source_id_tag'].split('_')[1])).execute()
                                        supabase.table("knowledge_blacklist").insert({"query": user_q, "source_id": d['source_id_tag'], "reason": "ë„ë©”ì¸ êµì •"}).execute()
                                        st.rerun()
                else:
                    st.warning(f"âš ï¸ {target_domain} ë„ë©”ì¸ì—ì„œ ì§€ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e: st.error(f"ì¡°íšŒ ì‹¤íŒ¨ (V113): {e}")

# --- 4. ë°ì´í„° ì „ì²´ ê´€ë¦¬ (V113: ë§ˆì´ê·¸ë ˆì´ì…˜ ì—ëŸ¬ ìˆ˜ì • ì™„ë£Œ) ---
elif st.session_state.page_mode == "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬":
    t1, t2, t3, t4, t5 = st.tabs(["ğŸ“Š ë¡œê·¸ ë¶„ì„", "ğŸ“ ê²½í—˜ ë¦¬íŒŒì´ë„ˆ", "ğŸ“„ ë§¤ë‰´ì–¼ ë¦¬íŒŒì´ë„ˆ", "ğŸš« êµì • ê¸°ë¡", "ğŸ§¹ ë°ì´í„° ëŒ€ì²­ì†Œ"])
    
    with t5:
        st.subheader("ğŸ§¹ ê¸°ì¡´ ë°ì´í„° ì§€ëŠ¥í˜• ë¶„ë¥˜")
        target_table = st.radio("ë¶„ë¥˜ ëŒ€ìƒ", ["ê²½í—˜ ì§€ì‹", "ë§¤ë‰´ì–¼ ì§€ì‹"], horizontal=True)
        table_name = "knowledge_base" if target_table == "ê²½í—˜ ì§€ì‹" else "manual_base"
        
        unlabeled = supabase.table(table_name).select("id", count="exact").is_("domain", "null").execute()
        st.metric("ë¶„ë¥˜ ëŒ€ê¸° ì¤‘", f"{unlabeled.count or 0} ê±´")
        
        if st.button("ğŸš€ AI ìë™ ë¶„ë¥˜ ì‹œì‘"):
            rows = supabase.table(table_name).select("*").is_("domain", "null").limit(20).execute().data
            if not rows: st.success("ğŸ‰ ëª¨ë“  ë°ì´í„°ê°€ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                with st.status("ğŸ—ï¸ ì§€ëŠ¥í˜• ë¶„ë¥˜ ì§„í–‰ ì¤‘...", expanded=True) as status:
                    for r in rows:
                        content = r.get('solution') or r.get('content') or ""
                        result = ai_classify_data(content[:2000])
                        # [V113 í•µì‹¬ Fix] ê²°ê³¼ê°’ ì¡´ì¬ ì—¬ë¶€ ë° ë”•ì…”ë„ˆë¦¬ ì—¬ë¶€ ì² ì € ê²€ì¦
                        if result and isinstance(result, dict):
                            supabase.table(table_name).update({
                                "domain": result.get('domain', 'ê¸°ìˆ ìì‚°'),
                                "sub_category": result.get('sub_category', 'ì¼ë°˜'),
                                "measurement_item": result.get('item', r.get('measurement_item'))
                            }).eq("id", r['id']).execute()
                            st.write(f"âœ… ID {r['id']}: [{result.get('domain', 'ê¸°ìˆ ìì‚°')}] ë¶„ë¥˜ ì™„ë£Œ")
                        else:
                            # ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì ìš©í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
                            supabase.table(table_name).update({"domain": "ê¸°ìˆ ìì‚°"}).eq("id", r['id']).execute()
                            st.write(f"âš ï¸ ID {r['id']}: ë¶„ì„ ì‹¤íŒ¨ (ê¸°ìˆ ìì‚° ê¸°ë³¸ í• ë‹¹)")
                    status.update(label="ë¶„ë¥˜ ì™„ë£Œ!", state="complete")
                st.rerun()

# --- 2, 3, 5, 6 ë©”ë‰´ (ì•ˆì •í™” ë¡œì§ ìœ ì§€) ---
elif st.session_state.page_mode == "ğŸ“ ì§€ì‹ ë“±ë¡":
    st.subheader("ğŸ“ ì‹ ê·œ ì§€ì‹ ë“±ë¡")
    with st.form("reg_v113", clear_on_submit=True):
        f_dom = st.selectbox("ë„ë©”ì¸", ["ê¸°ìˆ ìì‚°", "í–‰ì •ì ˆì°¨", "ë³µì§€ìƒí™œ"])
        f_mfr, f_iss, f_sol = st.text_input("ì œì¡°ì‚¬/ìƒí˜¸"), st.text_input("ì œëª©"), st.text_area("ë‚´ìš©")
        if st.form_submit_button("ì €ì¥"):
            supabase.table("knowledge_base").insert({"domain": f_dom, "manufacturer": f_mfr, "issue": f_iss, "solution": f_sol, "embedding": get_embedding(f"{f_dom} {f_mfr} {f_iss} {f_sol}")}).execute()
            st.success("ë“±ë¡ ì™„ë£Œ!")

elif st.session_state.page_mode == "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡":
    st.subheader("ğŸ“„ ë§¤ë‰´ì–¼ ë“±ë¡")
    up_f = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
    if up_f:
        f_dom = st.selectbox("ë¬¸ì„œ ë„ë©”ì¸", ["ê¸°ìˆ ìì‚°", "í–‰ì •ì ˆì°¨", "ë³µì§€ìƒí™œ"])
        if st.button("ğŸš€ ì§€ì‹ í•™ìŠµ ì‹œì‘"):
            up_f.seek(0)
            pdf_r = PyPDF2.PdfReader(io.BytesIO(up_f.read()))
            all_t = "\n".join([p.extract_text() for p in pdf_r.pages if p.extract_text()])
            chunks = [all_t[i:i+1000] for i in range(0, len(all_t), 800)]
            p_bar = st.progress(0)
            for i, chunk in enumerate(chunks):
                supabase.table("manual_base").insert({"domain": f_dom, "content": clean_text_for_db(chunk), "file_name": up_f.name, "embedding": get_embedding(chunk)}).execute()
                p_bar.progress((i+1)/len(chunks))
            st.success("í•™ìŠµ ì™„ë£Œ!"); st.rerun()

elif st.session_state.page_mode == "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ (Q&A)":
    st.subheader("ğŸ’¬ ì†Œí†µ ê³µê°„") # ì´ì „ ë²„ì „ ë¡œì§ ìœ ì§€

elif st.session_state.page_mode == "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ":
    st.subheader("ğŸ†˜ í•´ê²°ì´ í•„ìš”í•œ ì§ˆë¬¸") # ì´ì „ ë²„ì „ ë¡œì§ ìœ ì§€
