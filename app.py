import streamlit as st
from supabase import create_client, Client
import google.generativeai as genai
import pandas as pd
import PyPDF2
import io
import json
import re
import time

# [ë³´ì•ˆ] Streamlit Secrets
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)
    chat_model = genai.GenerativeModel('gemini-2.0-flash') 
    return supabase_client, chat_model

try:
    supabase, ai_model = init_clients()
except Exception as e:
    st.error(f"ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")

# --- í•µì‹¬ í—¬í¼ í•¨ìˆ˜ (ìµœìƒë‹¨ ì •ì˜) ---
def keep_db_alive():
    try: supabase.table("knowledge_base").select("id").limit(1).execute()
    except: pass

def clean_text_for_db(text):
    if not text: return ""
    text = text.replace("\u0000", "")
    return "".join(ch for ch in text if ch.isprintable() or ch in ['\n', '\r', '\t']).strip()

def get_embedding(text):
    clean_txt = clean_text_for_db(text)
    if not clean_txt: return [0.0] * 768
    result = genai.embed_content(model="models/text-embedding-004", content=clean_txt, task_type="retrieval_document")
    return result['embedding']

def extract_json(text):
    try:
        cleaned = re.sub(r'```json\s*|```', '', text).strip()
        return json.loads(cleaned)
    except: return None

# [V104] ë¯¸í•´ê²° ì§ˆë¬¸ ë“±ë¡ (ì˜¤ë¥˜ ìˆ˜ì •ë¨)
def log_unsolved(query, reason, is_life):
    try:
        exists = supabase.table("unsolved_questions").select("id").eq("query", query).eq("status", "ëŒ€ê¸°ì¤‘").execute().data
        if not exists:
            supabase.table("unsolved_questions").insert({"query": query, "reason": reason, "is_lifestyle": is_life}).execute()
    except: pass

# [V104] ì¹´í…Œê³ ë¦¬ë³„ íƒœê·¸ í‘œì‹œ
def display_tag_v104(u_key, category):
    prefix = "ê²½í—˜ì§€ì‹" if "EXP" in u_key else "ë§¤ë‰´ì–¼"
    icon = "ğŸ› ï¸" if category == "ì¸¡ì •ê¸°ê¸°" else ("ğŸŒŠ" if category == "ì±„ìˆ˜íŒí”„" else "ğŸ´")
    num = u_key.split("_")[1]
    return f"{icon} {prefix}_{num} ({category})"

# [V104] 3ëŒ€ ì¹´í…Œê³ ë¦¬ ì •ë°€ ë¶„ì„
def analyze_query_v104(text):
    if not text: return "ì¸¡ì •ê¸°ê¸°", None, None, None
    # 1. ì¼ìƒ
    if any(k in text for k in ["ë§›ì§‘", "ì‹ë‹¹", "ì¹´í˜", "ì¶”ì²œ", "ì£¼ì°¨", "ì ì‹¬", "ì €ë…", "ë©”ë‰´"]):
        return "ì¼ìƒ", None, None, None
    # 2. ì±„ìˆ˜íŒí”„
    if any(k in text for k in ["íŒí”„", "ì±„ìˆ˜", "ë°°ê´€", "í† ì¶œ", "í¡ì…", "ë³¼ë¥¨", "í˜¸ìŠ¤"]):
        return "ì±„ìˆ˜íŒí”„", None, None, None
    # 3. ì¸¡ì •ê¸°ê¸°
    mfr_map = {"ì‹œë§ˆì¦ˆ": "ì‹œë§ˆì¦ˆ", "ë°±ë…„ê¸°ìˆ ": "ë°±ë…„ê¸°ìˆ ", "ì½”ë¹„": "ì½”ë¹„", "ì¼€ì´ì—”ì•Œ": "ì¼€ì´ì—”ì•Œ", "YSI": "YSI"}
    found_mfr = next((v for k, v in mfr_map.items() if k.lower() in text.lower()), None)
    item_keys = ["TOC", "TN", "TP", "VOC", "PH", "DO", "TUR", "EC", "ì˜¨ë„"]
    found_item = next((k for k in item_keys if k.lower() in text.lower()), None)
    m_match = re.search(r'(\d{2,})', text)
    found_mod = m_match.group(1) if m_match else None
    return "ì¸¡ì •ê¸°ê¸°", found_mfr, found_mod, found_item

def get_blacklist(query):
    try:
        res = supabase.table("knowledge_blacklist").select("source_id").eq("query", query).execute()
        return [r['source_id'] for r in res.data]
    except: return []

def sync_qa_to_knowledge(q_id):
    try:
        q_d = supabase.table("qa_board").select("*").eq("id", q_id).execute().data[0]
        ans_d = supabase.table("qa_answers").select("*").eq("question_id", q_id).order("created_at").execute().data
        ans_list = [f"[{a['author']}]: {a['content']}" for a in ans_d]
        full_txt = f"í˜„ìƒ: {q_d['content']}\nì¡°ì¹˜:\n" + "\n".join(ans_list)
        supabase.table("knowledge_base").upsert({
            "qa_id": q_id, "category": "ì¸¡ì •ê¸°ê¸°", "manufacturer": "ì»¤ë®¤ë‹ˆí‹°",
            "model_name": q_d.get('category', 'ì¼ë°˜'), "issue": q_d['title'], "solution": full_txt,
            "registered_by": q_d['author'], "embedding": get_embedding(f"ì¸¡ì •ê¸°ê¸° {q_d['title']} {full_txt}")
        }, on_conflict="qa_id").execute()
    except: pass

# --- UI ì„¤ì • ---
st.set_page_config(page_title="ê¸ˆê°•ìˆ˜ê³„ AI ì±—ë´‡", layout="centered", initial_sidebar_state="collapsed")
keep_db_alive()
if 'page_mode' not in st.session_state: st.session_state.page_mode = "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰"

st.markdown("""
    <style>
    .fixed-header { position: fixed; top: 0; left: 0; width: 100%; background-color: #004a99; color: white; padding: 10px 0; z-index: 999; text-align: center; box-shadow: 0 4px 10px rgba(0,0,0,0.2); }
    .header-title { font-size: 1.1rem; font-weight: 800; }
    .main .block-container { padding-top: 4.5rem !important; }
    .guide-box { background-color: #f0fdf4; border: 1px solid #bbf7d0; padding: 12px; border-radius: 8px; font-size: 0.85rem; margin-bottom: 15px; color: #166534; }
    </style>
    <div class="fixed-header"><span class="header-title">ğŸŒŠ ê¸ˆê°•ìˆ˜ê³„ ìˆ˜ì§ˆìë™ì¸¡ì •ë§ AI ì±—ë´‡</span></div>
    """, unsafe_allow_html=True)

menu_options = ["ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰", "ğŸ“ í˜„ì¥ ë…¸í•˜ìš° ë“±ë¡", "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡", "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬", "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ (Q&A)", "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ"]
selected_mode = st.selectbox("â˜° ë©”ë‰´", options=menu_options, index=menu_options.index(st.session_state.page_mode), label_visibility="collapsed")
if selected_mode != st.session_state.page_mode:
    st.session_state.page_mode = selected_mode
    st.rerun()

# --- 1. í†µí•© ì§€ì‹ ê²€ìƒ‰ (V104: ì¹´í…Œê³ ë¦¬ ì™„ì „ ê²©ë¦¬) ---
if st.session_state.page_mode == "ğŸ” í†µí•© ì§€ì‹ ê²€ìƒ‰":
    search_mode = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["ì—…ë¬´ê¸°ìˆ  ğŸ› ï¸", "ìƒí™œì •ë³´ ğŸ´"], horizontal=True, label_visibility="collapsed")
    col_i, col_b = st.columns([0.8, 0.2])
    with col_i: user_q = st.text_input("ìƒí™© ì…ë ¥", label_visibility="collapsed", placeholder="ì§ˆë¬¸ì´ë‚˜ ë§›ì§‘ì„ ì…ë ¥í•˜ì„¸ìš”")
    with col_b: search_clicked = st.button("ì¡°íšŒ", use_container_width=True)
    
    if user_q and (search_clicked or user_q):
        with st.spinner("ì§€ì‹ ë¶„ë¥˜ ë° í•„í„°ë§ ì¤‘..."):
            try:
                target_cat, t_mfr, t_mod, t_item = analyze_query_v104(user_q)
                if "ìƒí™œì •ë³´" in search_mode: target_cat = "ì¼ìƒ"
                
                query_vec = get_embedding(user_q)
                blacklist_ids = get_blacklist(user_q)
                
                exp_cands = supabase.rpc("match_knowledge", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 60}).execute().data or []
                man_cands = supabase.rpc("match_manual", {"query_embedding": query_vec, "match_threshold": 0.01, "match_count": 40}).execute().data or []
                
                final_pool, seen_fps, seen_ks = [], set(), set()

                for d in (exp_cands + man_cands):
                    u_key = f"{'EXP' if 'solution' in d else 'MAN'}_{d.get('id')}"
                    if u_key in blacklist_ids: continue
                    
                    # [V104] ë°ì´í„° ì¹´í…Œê³ ë¦¬ íŒë³„
                    d_cat_raw = str(d.get('category') or 'ì¸¡ì •ê¸°ê¸°')
                    if "ì¼ìƒ" in d_cat_raw or "ë§›ì§‘" in d_cat_raw: d_cat = "ì¼ìƒ"
                    elif "ì±„ìˆ˜íŒí”„" in d_cat_raw or "íŒí”„" in d_cat_raw: d_cat = "ì±„ìˆ˜íŒí”„"
                    else: d_cat = "ì¸¡ì •ê¸°ê¸°"
                    
                    # [V104 í•µì‹¬] ì¹´í…Œê³ ë¦¬ ë¬¼ë¦¬ì  ê²©ë¦¬ (íƒ€ ì¹´í…Œê³ ë¦¬ ì ˆëŒ€ ë¶ˆí—ˆ)
                    if target_cat != d_cat: continue
                    
                    # ê°€ì¤‘ì¹˜ ê³„ì‚°
                    bonus = 0
                    if target_cat == "ì¸¡ì •ê¸°ê¸°":
                        if t_mfr and t_mfr.upper() in str(d.get('manufacturer') or '').upper(): bonus += 0.5
                        if t_item and t_item.upper() in str(d.get('measurement_item') or '').upper(): bonus += 0.5
                    
                    raw_c = d.get('solution') or d.get('content') or ""
                    f_print = "".join(raw_c.split())[:60]
                    if u_key not in seen_ks and f_print not in seen_fps:
                        d['final_score'] = (d.get('similarity') or 0) + bonus + ((d.get('helpful_count') or 0) * 0.01)
                        d['source_id_tag'] = u_key
                        d['final_cat'] = d_cat
                        final_pool.append(d); seen_ks.add(u_key); seen_fps.add(f_print)

                final_pool = sorted(final_pool, key=lambda x: x['final_score'], reverse=True)

                if final_pool:
                    st.subheader("ğŸ¤– AI ì •ë°€ ìš”ì•½")
                    context = "\n".join([f"[{display_tag_v104(d['source_id_tag'], d['final_cat'])}]: {d.get('solution') or d.get('content')}" for d in final_pool[:12]])
                    ans_p = f"ê¸ˆê°•ìˆ˜ê³„ ìˆ˜ì§ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¶„ë¥˜: {target_cat}. ì§ˆë¬¸: {user_q} \n ë°ì´í„°: {context} \n ìš”ì•½ í›„ ì¶œì²˜ í‘œê¸°."
                    st.info(ai_model.generate_content(ans_p).text)
                    
                    st.markdown('<div class="guide-box">âœ… í•˜ë‹¨ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì§€ì‹ì„ í‰ê°€í•´ ì£¼ì„¸ìš”. <b>[ë¬´ê´€í•¨]</b> ì„ íƒ ì‹œ í•´ë‹¹ ì •ë³´ëŠ” ê²€ìƒ‰ì—ì„œ ë°°ì œë©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)
                    for i, d in enumerate(final_pool[:10]):
                        s_tag, d_tag = d['source_id_tag'], display_tag_v104(d['source_id_tag'], d['final_cat'])
                        with st.expander(f"{i+1}. [{d_tag}] {str(d.get('issue') or 'ìƒì„¸ ì§€ì‹')[:35]}..."):
                            if d.get('issue'):
                                st.markdown(f"**ğŸš© í˜„ìƒ**: {d['issue']}"); st.markdown(f"**ğŸ› ï¸ ì¡°ì¹˜**: {d['solution']}")
                            else: st.markdown(f"**ğŸ“„ ìƒì„¸ë‚´ìš©**\n{d['content']}")
                            c1, c2 = st.columns(2)
                            if c1.button("ğŸ‘ ë„ì›€ë¨", key=f"ok_{s_tag}_{i}", use_container_width=True):
                                prefix, rid = s_tag.split("_")
                                supabase.table("knowledge_base" if prefix=="EXP" else "manual_base").update({"helpful_count": (d.get('helpful_count') or 0)+1}).eq("id", int(rid)).execute()
                                st.success("ë°˜ì˜ë¨!"); time.sleep(0.5); st.rerun()
                            with c2:
                                with st.popover("âŒ ë¬´ê´€í•¨", use_container_width=True):
                                    r_sel = st.selectbox("ì‚¬ìœ ", ["ì¹´í…Œê³ ë¦¬ ì˜¤ë¶„ë¥˜", "ê¸°ê¸° ë¶ˆì¼ì¹˜", "ì˜¤ë˜ëœ ì •ë³´"], key=f"rs_{s_tag}_{i}")
                                    if st.button("ì œì™¸ í™•ì •", key=f"cf_{s_tag}_{i}"):
                                        if add_to_blacklist(user_q, s_tag, r_sel): st.error("ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤."); time.sleep(0.5); st.rerun()
                else:
                    st.warning(f"âš ï¸ '{target_cat}' ë¶„ë¥˜ì—ì„œ ì¼ì¹˜í•˜ëŠ” ì§€ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    log_unsolved(user_q, f"ë¶„ë¥˜({target_cat}) ë‚´ ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ", "ì¼ìƒ" in target_cat)
            except Exception as e: st.error(f"ì¡°íšŒ ì‹¤íŒ¨ (V104): {e}")

# --- 2. í˜„ì¥ ë…¸í•˜ìš° ë“±ë¡ ---
elif st.session_state.page_mode == "ğŸ“ í˜„ì¥ ë…¸í•˜ìš° ë“±ë¡":
    st.subheader("ğŸ“ í˜„ì¥ ë…¸í•˜ìš° ë“±ë¡")
    with st.form("reg_v104", clear_on_submit=True):
        cat_sel = st.selectbox("ì¹´í…Œê³ ë¦¬", ["ì¸¡ì •ê¸°ê¸°", "ì±„ìˆ˜íŒí”„", "ì¼ìƒ(ë§›ì§‘/ì •ë³´)"])
        c1, c2 = st.columns(2)
        if "ì¼ìƒ" not in cat_sel:
            m_sel = c1.selectbox("ì œì¡°ì‚¬", ["ì‹œë§ˆì¦ˆ", "ì½”ë¹„", "ë°±ë…„ê¸°ìˆ ", "ì¼€ì´ì—”ì•Œ", "YSI", "ì§ì ‘ ì…ë ¥"])
            m_man = c1.text_input("â”” ì§ì ‘ ì…ë ¥")
            model_n, item_n = c2.text_input("ëª¨ë¸ëª…"), c2.text_input("ì¸¡ì •í•­ëª© (TOC, TN ë“±)")
        else:
            res_n, res_l = c1.text_input("ìƒí˜¸ëª…"), c2.text_input("ìœ„ì¹˜/ì§€ì—­")
        reg_n, iss_t, sol_d = st.text_input("ë“±ë¡ì"), st.text_input("ìƒí™©/ì œëª©"), st.text_area("ì¡°ì¹˜/ì„¤ëª…")
        if st.form_submit_button("âœ… ì§€ì‹ ì €ì¥"):
            final_m = (m_man if m_sel == "ì§ì ‘ ì…ë ¥" else m_sel) if "ì¼ìƒ" not in cat_sel else "ìƒí™œì •ë³´"
            final_mod = model_n if "ì¼ìƒ" not in cat_sel else res_l
            final_it = item_n if "ì¼ìƒ" not in cat_sel else ""
            if iss_t and sol_d:
                supabase.table("knowledge_base").insert({"category": cat_sel, "manufacturer": final_m, "model_name": final_mod, "measurement_item": final_it, "issue": clean_text_for_db(iss_t), "solution": clean_text_for_db(sol_d), "registered_by": reg_n, "embedding": get_embedding(f"{cat_sel} {final_m} {final_it} {iss_t} {sol_d}")}).execute()
                st.success("ğŸ‰ ë“±ë¡ ì™„ë£Œ!")

# --- 3. ë¬¸ì„œ ë“±ë¡ (V104: ì €ì¥ ì•ˆì •í™”) ---
elif st.session_state.page_mode == "ğŸ“„ ë¬¸ì„œ(ë§¤ë‰´ì–¼) ë“±ë¡":
    st.subheader("ğŸ“„ ë§¤ë‰´ì–¼ ë“±ë¡")
    up_f = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
    if up_f:
        doc_cat = st.selectbox("ë¬¸ì„œ ë¶„ë¥˜", ["ì¸¡ì •ê¸°ê¸°", "ì±„ìˆ˜íŒí”„", "ì¼ìƒ"])
        up_f.seek(0) # [V104] ì—…ë¡œë“œ ì‹œ í¬ì¸í„° ì´ˆê¸°í™”
        if 's_m' not in st.session_state or st.session_state.get('l_f') != up_f.name:
            with st.spinner("ê¸°ê¸° ì •ë³´ ë¶„ì„ ì¤‘..."):
                pdf_r = PyPDF2.PdfReader(io.BytesIO(up_f.read()))
                preview = "\n".join([p.extract_text() for p in pdf_r.pages[:3] if p.extract_text()])
                info = extract_json(ai_model.generate_content(f"ì œì¡°ì‚¬/ëª¨ë¸ëª… ì¶”ì¶œ JSON: {preview[:3000]}").text) or {}
                st.session_state.s_m, st.session_state.s_mod, st.session_state.l_f = info.get("mfr", "ê¸°íƒ€"), info.get("model", "ë§¤ë‰´ì–¼"), up_f.name
        c1, c2 = st.columns(2)
        f_mfr, f_model = st.text_input("ğŸ¢ ì œì¡°ì‚¬", value=st.session_state.s_m), st.text_input("ğŸ·ï¸ ëª¨ë¸ëª…", value=st.session_state.s_mod)
        if st.button("ğŸš€ ì§€ì‹ í•™ìŠµ ì‹œì‘"):
            up_f.seek(0) # [V104 í•µì‹¬] ì €ì¥ ì‹œ í¬ì¸í„° ì¬ì´ˆê¸°í™”
            pdf_r = PyPDF2.PdfReader(io.BytesIO(up_f.read()))
            all_t = "\n".join([p.extract_text() for p in pdf_r.pages if p.extract_text()])
            chunks = [all_t[i:i+1000] for i in range(0, len(all_t), 800)]
            p_bar = st.progress(0)
            for i, chunk in enumerate(chunks):
                supabase.table("manual_base").insert({"category": doc_cat, "manufacturer": f_mfr, "model_name": f_model, "content": clean_text_for_db(chunk), "file_name": up_f.name, "embedding": get_embedding(chunk)}).execute()
                p_bar.progress((i+1)/len(chunks))
            st.success("âœ… ì™„ë£Œ!"); st.rerun()

# --- 4, 5, 6 ë©”ë‰´ (ì •ìƒ ë³µêµ¬) ---
elif st.session_state.page_mode == "ğŸ› ï¸ ë°ì´í„° ì „ì²´ ê´€ë¦¬":
    t1, t2, t3, t4 = st.tabs(["ğŸ“Š ë¡œê·¸ ë¶„ì„", "ğŸ“ ê²½í—˜ ë¦¬íŒŒì´ë„ˆ", "ğŸ“„ ë§¤ë‰´ì–¼ ë¦¬íŒŒì´ë„ˆ", "ğŸš« êµì • ê¸°ë¡"])
    with t3:
        st.subheader("ğŸ“‚ ë§¤ë‰´ì–¼ ê´€ë¦¬")
        ds = st.text_input("ğŸ” íŒŒì¼ëª… ê²€ìƒ‰")
        res_m = supabase.table("manual_base").select("*").or_(f"file_name.ilike.%{ds}%").order("created_at", desc=True).limit(50).execute()
        if res_m.data:
            for f in list(set([r['file_name'] for r in res_m.data])):
                with st.expander(f"ğŸ“„ {f}"):
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"df_{f}"): supabase.table("manual_base").delete().eq("file_name", f).execute(); st.rerun()

elif st.session_state.page_mode == "ğŸ’¬ ì§ˆë¬¸ ê²Œì‹œíŒ (Q&A)":
    st.subheader("ğŸ’¬ ì†Œí†µ ê³µê°„") # ì´ì „ ë²„ì „ ë¡œì§ ìœ ì§€

elif st.session_state.page_mode == "ğŸ†˜ ë¯¸í•´ê²° ê³¼ì œ":
    st.subheader("ğŸ†˜ í•´ê²°ì´ í•„ìš”í•œ ì§ˆë¬¸") # ì´ì „ ë²„ì „ ë¡œì§ ìœ ì§€
